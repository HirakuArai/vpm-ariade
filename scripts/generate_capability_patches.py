import os
import json
from openai import OpenAI

# ãƒ‘ã‚¹è¨­å®š
PRIORITY_PATH = "docs/capability_priorities.json"
CORE_DIR = "core"
PATCH_DIR = "patches"

# APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# GPTãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
SYSTEM_PROMPT = """
ã‚ãªãŸã¯ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼AI Kaiã®èƒ½åŠ›æ‹¡å¼µã‚’æ”¯æ´ã™ã‚‹AIã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã§ã™ã€‚

ä»¥ä¸‹ã®æ©Ÿèƒ½IDã«å¯¾ã—ã¦ã€Kai ãŒä½¿ç”¨ã™ã‚‹ Python é–¢æ•°ã®ã‚¹ã‚±ãƒ«ãƒˆãƒ³ã‚’æ—¥æœ¬èªã§ä½œæˆã—ã¦ãã ã•ã„ã€‚

è¦ä»¶:
- é–¢æ•°åã¯æ©Ÿèƒ½IDã«æº–æ‹ 
- docstringï¼ˆèª¬æ˜ã‚³ãƒ¡ãƒ³ãƒˆï¼‰ã¯ã™ã¹ã¦æ—¥æœ¬èªã§è¨˜è¿°ã—ã¦ãã ã•ã„
- å¼•æ•°ã€æˆ»ã‚Šå€¤ã€æƒ³å®šã•ã‚Œã‚‹ä½¿ã„æ–¹ã‚’æ˜è¨˜ã—ã¦ãã ã•ã„
- å®Ÿè£…å†…å®¹ã¯æœªå®Œæˆï¼ˆpass ã®ã¾ã¾ã§æ§‹ã„ã¾ã›ã‚“ï¼‰
- ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã®ãƒãƒ¼ã‚¯ï¼ˆ```python ãªã©ï¼‰ã¯ä¸è¦ã§ã™
"""

def extract_python_code_block(text):
    if "```python" in text:
        return text.split("```python")[1].split("```")[0].strip()
    return text.strip()

def load_priorities():
    with open(PRIORITY_PATH, "r", encoding="utf-8") as f:
        return json.load(f)

def request_skeleton(cap_id):
    user_prompt = f"æ©Ÿèƒ½ID: {cap_id}\nã“ã®æ©Ÿèƒ½ã®ç›®çš„ã‚’è¸ã¾ãˆã€KaiãŒä½¿ç”¨ã™ã‚‹Pythonã‚¹ã‚±ãƒ«ãƒˆãƒ³é–¢æ•°ã‚’1ã¤ä½œæˆã—ã¦ãã ã•ã„ã€‚"
    response = client.chat.completions.create(
        model="gpt-4-1106-preview",
        messages=[
            {"role": "system", "content": SYSTEM_PROMPT},
            {"role": "user", "content": user_prompt}
        ],
        temperature=0.3
    )
    return response.choices[0].message.content.strip()

def save_skeleton_file(cap_id, code_text):
    os.makedirs(CORE_DIR, exist_ok=True)
    file_path = os.path.join(CORE_DIR, f"{cap_id}.py")
    with open(file_path, "w", encoding="utf-8") as f:
        f.write(code_text)
    print(f"âœ… ã‚¹ã‚±ãƒ«ãƒˆãƒ³ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {file_path}")
    return file_path

def save_capability_patch(cap_id, reason):
    os.makedirs(PATCH_DIR, exist_ok=True)
    patch_path = os.path.join(PATCH_DIR, f"{cap_id}_capability.json")
    patch = {
        "id": cap_id,
        "name": cap_id.replace("_", " ").title(),
        "description": reason,
        "requires_confirm": True,
        "enabled": True
    }
    with open(patch_path, "w", encoding="utf-8") as f:
        json.dump(patch, f, indent=2, ensure_ascii=False)
    print(f"ğŸ“¦ capabilitiesç™»éŒ²ç”¨ã®ææ¡ˆã‚‚ä¿å­˜ã—ã¾ã—ãŸ: {patch_path}")

def main():
    priorities = load_priorities()
    sorted_items = sorted(priorities.items(), key=lambda x: {"high": 0, "medium": 1, "low": 2}[x[1]["priority"]])

    if not sorted_items:
        print("ğŸ“­ å„ªå…ˆåº¦ä»˜ãèƒ½åŠ›ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    cap_id, meta = sorted_items[0]
    print(f"ğŸ§  GPTã«ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆã‚’ä¾é ¼ä¸­: {cap_id}")
    raw_code = request_skeleton(cap_id)
    clean_code = extract_python_code_block(raw_code)

    print("\nğŸ“„ ç”Ÿæˆçµæœ:\n")
    print(clean_code)

    save_skeleton_file(cap_id, clean_code)
    save_capability_patch(cap_id, meta["reason"])

if __name__ == "__main__":
    main()
