{"resource": "code://core/handle_approval.py#handle_approval", "code": "def handle_approval(requester, document, approval_status):\n    \"\"\"\n    指定されたドキュメントの承認処理を行います。\n\n    Args:\n        requester (str): 承認を要求するユーザーの名前またはID。\n        document (str): 承認または非承認するドキュメントの名前またはID。\n        approval_status (bool): ドキュメントを承認する場合はTrue、非承認する場合はFalse。\n\n    Returns:\n        str: 承認処理の結果を説明するメッセージ。\n\n    使い方の例:\n        # ドキュメント \"Doc123\" をユーザー \"User456\" が承認する場合\n        result_message = handle_approval(\"User456\", \"Doc123\", True)\n        print(result_message)  # 承認が完了した旨のメッセージを出力\n\n        # ドキュメント \"Doc789\" をユーザー \"User101\" が非承認する場合\n        result_message = handle_approval(\"User101\", \"Doc789\", False)\n        print(result_message)  # 非承認が完了した旨のメッセージを出力\n    \"\"\"\n    pass", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://core/structure_scanner.py#scan_project_structure", "code": "def scan_project_structure(base_path: str = \".\") -> Dict[str, List[str]]:\n    \"\"\"\n    プロジェクトのディレクトリ構造と主要ファイル一覧を辞書形式で返す。\n    \"\"\"\n    structure = {}\n    for root, dirs, files in os.walk(base_path):\n        if any(skip in root for skip in [\".venv\", \"__pycache__\", \".git\"]):\n            continue\n        rel_root = os.path.relpath(root, base_path)\n        if rel_root == \".\":\n            rel_root = \"\"\n        structure[rel_root] = sorted(files)\n    return structure", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://core/self_introspection.py#_norm", "code": "def _norm(val: str | None) -> str | None:\n    \"\"\"大小文字・前後空白を無視した ID 正規化\"\"\"\n    return None if val is None else val.strip().lower()", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://core/self_introspection.py#_id_set", "code": "def _id_set(lst: List[Dict[str, Any]]) -> Set[str]:\n    return {_norm(c.get(\"id\")) for c in lst if _norm(c.get(\"id\"))}", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://core/self_introspection.py#_fingerprint", "code": "def _fingerprint() -> str:\n    path = pathlib.Path(__file__)\n    md5 = hashlib.md5(path.read_bytes()).hexdigest()[:8]\n    mtime = dt.datetime.fromtimestamp(path.stat().st_mtime).strftime(\"%Y-%m-%d %H:%M:%S\")\n    return f\"{md5}@{mtime}\"", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://core/capabilities_registry.py#decorator", "code": "def decorator(fn):\n        fn._kai_capability = {\n            \"id\": id,\n            \"name\": name,\n            \"description\": description,\n            \"requires_confirm\": requires_confirm,\n            \"enabled\": enabled\n        }\n        return fn", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://core/git_ops.py#push_all_important_files", "code": "def push_all_important_files():\n    try:\n        subprocess.run([\"git\", \"config\", \"--global\", \"user.name\", \"Kai Bot\"], check=True)\n        subprocess.run([\"git\", \"config\", \"--global\", \"user.email\", \"kai@example.com\"], check=True)\n\n        # 対象パターン\n        include_paths = [\n            \"data/*.json\",\n            \"data/structure_snapshot.json\",\n            \"output/*.json\",\n            \"conversations/*.md\",\n            \"logs/*.log\",\n            \"docs/*.md\",\n            \"core/**/*.py\",\n            \"scripts/*.py\"\n        ]\n\n        for pattern in include_paths:\n            subprocess.run([\"git\", \"add\", pattern], shell=False)\n\n        subprocess.run([\"git\", \"commit\", \"-m\", \"全重要ファイルを一括push\"], check=True)\n        subprocess.run([\n            \"git\", \"push\",\n            f\"https://{github_token}@github.com/HirakuArai/vpm-ariade.git\"\n        ], check=True)\n\n        print(\"✅ 重要ファイルを全てpushしました\", flush=True)\n\n    except subprocess.CalledProcessError as e:\n        print(\"❌ push_all_important_files エラー:\", e, flush=True)", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://core/run_code_analysis.py#main", "code": "def main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--file\", required=True, help=\"解析対象のPythonファイル\")\n    parser.add_argument(\"--mode\", choices=[\"functions\", \"classes\", \"variables\", \"all\"], default=\"all\")\n    args = parser.parse_args()\n\n    if args.mode in (\"functions\", \"all\"):\n        print(\"=== Functions ===\")\n        for f in extract_functions(args.file):\n            print(f\"- {f['name']}({', '.join(f['args'])}) @ line {f['lineno']}\")\n\n    if args.mode in (\"classes\", \"all\"):\n        print(\"\\n=== Classes ===\")\n        for c in extract_classes(args.file):\n            print(f\"- class {c['name']} (methods: {', '.join(c['methods'])}) @ line {c['lineno']}\")\n\n    if args.mode in (\"variables\", \"all\"):\n        print(\"\\n=== Variables ===\")\n        for v in extract_variables(args.file):\n            print(f\"- {v['name']} = {v['value']} ({v['type']}) @ line {v['lineno']}\")", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://core/log_utils.py#messages_to_text", "code": "def messages_to_text(messages):\n    text = \"\"\n    for m in messages:\n        role = m.get(\"role\", \"user\")\n        content = m.get(\"content\", \"\")\n        text += f\"{role.upper()}: {content}\\n\"\n    return text.strip()", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://core/enforcement.py#enforce_rules", "code": "def enforce_rules(action_context: dict) -> list:\n    \"\"\"\n    与えられたコンテキストに対し、kai_rules.json に基づくルール違反を検出する。\n    - action_context: {\n        \"action\": \"propose_doc_update\",\n        \"doc_type\": \"ondemand\",\n        \"approved\": False,\n        ...\n      }\n\n    Returns: 違反したルールの一覧（空リストなら問題なし）\n    \"\"\"\n    rules = load_rules()\n    violations = []\n\n    for rule in rules:\n        rid = rule.get(\"id\")\n        desc = rule.get(\"description\", \"\")\n        scope = rule.get(\"scope\")\n\n        # 例：特定ルールに対する簡易チェック（拡張可）\n        if rid == \"kai-on-demand-doc-block\":\n            if action_context.get(\"action\") in [\"propose_doc_update\", \"apply_update\"] and \\\n               action_context.get(\"doc_type\") == \"ondemand\":\n                violations.append(rule)\n\n        elif rid == \"kai-update-propose-approval\":\n            if action_context.get(\"action\") == \"apply_update\" and not action_context.get(\"approved\", False):\n                violations.append(rule)\n\n        elif rid == \"kai-single-doc-single-commit\":\n            if action_context.get(\"action\") == \"try_git_commit\" and \\\n               action_context.get(\"modified_docs\", 0) > 1:\n                violations.append(rule)\n\n        # TODO: 追加ルールチェック（将来）\n\n    return violations", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://core/manage_tasks.py#create_task", "code": "def create_task(title, description, due_date, priority):\n    \"\"\"\n    新しいタスクを作成し、保存する。\n    ...\n    \"\"\"\n    pass", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://core/manage_tasks.py#delete_task", "code": "def delete_task(task_id):\n    \"\"\"\n    指定されたIDのタスクを削除する。\n    ...\n    \"\"\"\n    pass", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://core/manage_tasks.py#list_tasks", "code": "def list_tasks(filter_by=None, order_by=None):\n    \"\"\"\n    保存されているタスクのリストを取得する。フィルターやソート順を指定できる。\n    ...\n    \"\"\"\n    pass", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://core/utils.py#read_file", "code": "def read_file(path):\n    \"\"\"\n    指定されたファイルを読み取り文字列として返す。存在しない場合は空文字列。\n    \"\"\"\n    return open(path, encoding=\"utf-8\").read() if os.path.exists(path) else \"\"", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://core/utils.py#write_file", "code": "def write_file(path, content):\n    \"\"\"\n    指定されたパスに文字列を保存する。\n    \"\"\"\n    with open(path, \"w\", encoding=\"utf-8\") as f:\n        f.write(content)", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://core/utils.py#ensure_output_dir", "code": "def ensure_output_dir(path=\"kai_generated\"):\n    \"\"\"\n    指定パスのディレクトリを作成（既に存在すれば何もしない）。\n    \"\"\"\n    os.makedirs(path, exist_ok=True)", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://core/utils.py#safe_mkdir", "code": "def safe_mkdir(path):\n    \"\"\"\n    指定されたディレクトリを作成（存在チェック付き）。\n    \"\"\"\n    os.makedirs(path, exist_ok=True)", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://core/decorator_inserter.py#insert_kai_decorator", "code": "def insert_kai_decorator(cap: Dict, *, dry_run=False) -> bool | str:\n    file_path = pathlib.Path(cap[\"filepath\"])\n    if not file_path.exists():\n        raise FileNotFoundError(file_path)\n\n    source_lines = file_path.read_text(encoding=\"utf-8\").splitlines()\n    tree = ast.parse(\"\\n\".join(source_lines))\n\n    target = next(\n        (n for n in ast.walk(tree)\n         if isinstance(n, ast.FunctionDef) and n.name == cap[\"name\"]),\n        None\n    )\n    if not target:\n        raise ValueError(f\"関数 `{cap['name']}` が {file_path} に見つかりません\")\n\n    idx = target.lineno - 1\n\n    # すでに直前に同じ装飾があるならスキップ\n    if \"@kai_capability\" in source_lines[idx - 1]:\n        return False\n\n    # 補完内容（description省略可）\n    decorator = f\"@kai_capability(id=\\\\\\\"{cap['name']}\\\\\\\", name=\\\\\\\"{cap['name'].replace('_',' ').title()}\\\\\\\", description=\\\\\\\"Kaiが {cap['name']} に関する能力を提供します。\\\\\\\", requires_confirm=False)\"\n\n    source_lines.insert(idx, decorator)\n    new_source = \"\\n\".join(source_lines) + \"\\n\"\n\n    if dry_run:\n        return new_source\n\n    file_path.write_text(new_source, encoding=\"utf-8\")\n    return True", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://core/kai_patch_applier.py#apply_gpt_patch", "code": "def apply_gpt_patch(markdown_text: str, fn_name: str, source_path: str = \"app.py\", auto_commit: bool = True) -> bool:\n    \"\"\"\n    GPTが返したMarkdown形式の修正提案（markdown_text）からコードブロックを抽出し、\n    指定された関数(fn_name)に上書きする。成功時に Git commit も実行。\n    \"\"\"\n    code = extract_code_from_markdown(markdown_text)\n    if not code:\n        print(\"❌ コードブロックが抽出できませんでした。\")\n        return False\n\n    success = replace_function_in_source(source_path, fn_name, code)\n    if success:\n        # ✅ Patch log を記録\n        instruction = (\n            st.session_state.get(\"fn_instruction\", \"\") if \"st\" in globals() else\n            f\"関数 `{fn_name}` を GPT により自動改修（Kai UIから）\"\n        )\n        log_patch(fn_name=fn_name, user_instruction=instruction, markdown_diff=markdown_text)\n\n        if auto_commit:\n            try_git_commit(source_path)\n            if os.path.exists(\"patch_history.json\"):\n                try_git_commit(\"patch_history.json\")\n\n    return success", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://core/discover_capabilities.py#discover_capabilities", "code": "def discover_capabilities(base_dir: str = \".\", full_scan: bool = False) -> list:\n    capabilities = []\n\n    # 走査対象\n    targets = [\n        Path(base_dir) / \"app.py\",\n        *(Path(base_dir) / \"core\").glob(\"*.py\")\n    ]\n\n    for file_path in targets:\n        if not file_path.is_file():\n            continue\n\n        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n            tree = ast.parse(f.read(), filename=str(file_path))\n\n        for node in ast.walk(tree):\n            if isinstance(node, ast.FunctionDef):\n                meta = {\n                    \"id\": None,\n                    \"name\": node.name,\n                    \"description\": \"\",\n                    \"requires_confirm\": False,\n                    \"enabled\": True,\n                    \"decorated\": False\n                }\n                # デコレータチェック\n                for deco in node.decorator_list or []:\n                    if isinstance(deco, ast.Call) and getattr(deco.func, \"id\", \"\") == \"kai_capability\":\n                        for keyword in deco.keywords:\n                            meta[keyword.arg] = ast.literal_eval(keyword.value)\n                        meta[\"decorated\"] = True\n                if full_scan or meta[\"decorated\"]:\n                    capabilities.append(meta)\n\n    return capabilities", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://core/stub_writer.py#write_stub_file", "code": "def write_stub_file(id: str, code: str):\n    path = os.path.join(OUTPUT_DIR, f\"{id}.py\")\n    with open(path, \"w\", encoding=\"utf-8\") as f:\n        f.write(code)", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://core/stub_writer.py#write_metadata_file", "code": "def write_metadata_file(id: str, name: str, description: str):\n    meta = {\n        \"id\": id,\n        \"name\": name,\n        \"description\": description,\n        \"requires_confirm\": False,\n        \"enabled\": True\n    }\n    path = os.path.join(OUTPUT_DIR, f\"{id}_capability.json\")\n    with open(path, \"w\", encoding=\"utf-8\") as f:\n        json.dump(meta, f, ensure_ascii=False, indent=2)", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://core/code_rewriter.py#replace_function_in_source", "code": "def replace_function_in_source(source_path: str, fn_name: str, new_code: str) -> bool:\n    try:\n        with open(source_path, \"r\", encoding=\"utf-8\") as f:\n            source_lines = f.readlines()\n            tree = ast.parse(\"\".join(source_lines))\n\n        for node in tree.body:\n            if isinstance(node, ast.FunctionDef) and node.name == fn_name:\n                start = node.lineno - 1\n                end = node.end_lineno if hasattr(node, \"end_lineno\") else node.lineno + 5\n                break\n        else:\n            print(f\"❌ 関数 '{fn_name}' が見つかりませんでした。\")\n            return False\n\n        # new_code をインデント補正して挿入\n        new_code_lines = [line + \"\\n\" for line in new_code.strip().splitlines()]\n        updated_lines = source_lines[:start] + new_code_lines + source_lines[end:]\n\n        with open(source_path, \"w\", encoding=\"utf-8\") as f:\n            f.writelines(updated_lines)\n\n        print(f\"✅ 関数 '{fn_name}' を上書きしました。\")\n        return True\n\n    except Exception as e:\n        print(f\"❌ 書き換えエラー: {e}\")\n        return False", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://core/capabilities_diff.py#compare_capabilities", "code": "def compare_capabilities(ast_caps: List[Dict[str, Any]], json_caps: List[Dict[str, Any]]) -> Dict[str, List[Dict[str, Any]]]:\n    \"\"\"\n    AST結果とJSON定義を比較し、差分（未登録・不一致）を返す。\n\n    Returns:\n        {\n            \"missing_in_json\": [...],\n            \"mismatched\": [...]\n        }\n    \"\"\"\n    json_index = {cap[\"id\"]: cap for cap in json_caps if cap.get(\"id\")}\n    ast_index = {cap[\"id\"]: cap for cap in ast_caps if cap.get(\"id\")}\n\n    missing = []\n    mismatched = []\n\n    for id_, ast_cap in ast_index.items():\n        json_cap = json_index.get(id_)\n        if not json_cap:\n            missing.append(ast_cap)\n        else:\n            # 比較項目：name, description, requires_confirm, enabled\n            diffs = {}\n            for key in [\"name\", \"description\", \"requires_confirm\", \"enabled\"]:\n                if ast_cap.get(key) != json_cap.get(key):\n                    diffs[key] = {\n                        \"json\": json_cap.get(key),\n                        \"ast\": ast_cap.get(key)\n                    }\n            if diffs:\n                mismatched.append({\n                    \"id\": id_,\n                    \"differences\": diffs\n                })\n\n    return {\n        \"missing_in_json\": missing,\n        \"mismatched\": mismatched\n    }", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://core/capabilities_diff.py#format_diff_for_output", "code": "def format_diff_for_output(diff_result: Dict[str, List[Dict[str, Any]]]) -> str:\n    \"\"\"\n    差分結果をMarkdown形式で整形し、出力用にする。\n    \"\"\"\n    lines = [\"# 🔍 Kai 自己能力差分チェック結果\", \"\"]\n\n    if diff_result[\"missing_in_json\"]:\n        lines.append(\"## 🟡 capabilities.jsonに未登録の関数\")\n        for cap in diff_result[\"missing_in_json\"]:\n            lines.append(f\"- `{cap.get('id')}`: {cap.get('name')}\")\n        lines.append(\"\")\n\n    if diff_result[\"mismatched\"]:\n        lines.append(\"## 🟠 属性不一致の関数\")\n        for mismatch in diff_result[\"mismatched\"]:\n            lines.append(f\"### 🔧 `{mismatch['id']}`\")\n            for key, change in mismatch[\"differences\"].items():\n                lines.append(f\"- `{key}`: JSON = {change['json']} → AST = {change['ast']}\")\n        lines.append(\"\")\n\n    if not lines[2:] and not lines[-1]:\n        lines.append(\"✅ 差分はありません。すべて一致しています。\")\n\n    return \"\\n\".join(lines)", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://scripts/test_enforcement.py#test_on_demand_doc_block", "code": "def test_on_demand_doc_block():\n    context = {\n        \"action\": \"propose_doc_update\",\n        \"doc_type\": \"ondemand\"\n    }\n    violations = enforce_rules(context)\n    assert any(r[\"id\"] == \"kai-on-demand-doc-block\" for r in violations), \"Expected violation not found\"", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://scripts/test_enforcement.py#test_multi_doc_commit", "code": "def test_multi_doc_commit():\n    context = {\n        \"action\": \"try_git_commit\",\n        \"modified_docs\": 2\n    }\n    violations = enforce_rules(context)\n    assert any(r[\"id\"] == \"kai-single-doc-single-commit\" for r in violations), \"Expected violation not found\"", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://scripts/test_enforcement.py#test_valid_action", "code": "def test_valid_action():\n    context = {\n        \"action\": \"try_git_commit\",\n        \"modified_docs\": 1\n    }\n    violations = enforce_rules(context)\n    assert len(violations) == 0, \"Unexpected violations detected\"", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://scripts/sync_kai_state.py#sync_kai", "code": "def sync_kai():\n    # 1. 最新の状態にgit pull\n    try_git_pull_safe()\n\n    # 2. 未処理ログの確認とドキュメント更新提案（自動承認）\n    unprocessed = check_unprocessed_logs()\n    updates = []\n    for fname in unprocessed:\n        doc_name = \"project_status.md\"  # 将来的にマッピング可能に\n        messages = load_yesterdays_log_as_messages(fname)\n        conv_text = messages_to_text(messages)\n        proposal = propose_doc_update(doc_name, conv_text)\n        apply_update(doc_name, proposal, auto_approve=True)\n        updates.append(doc_name)\n\n    # 3. kai_rules.json 再生成\n    subprocess.run([\"python\", \"scripts/generate_kai_rules.py\"])\n\n    # 4. 必要な能力リストを再生成（GPT）\n    subprocess.run([\"python\", \"scripts/scan_required_capabilities_gpt.py\"])\n\n    # 5. ルール違反の検出（例: 自動更新の中での誤操作チェック）\n    action_context = {\"action\": \"sync\", \"approved\": True}  # 必要に応じて拡張\n    rule_violations = enforce_rules(action_context)\n\n    # 6. ASTベースと登録済みcapabilitiesの差分を取得\n    ast_caps = load_ast_capabilities()\n    json_caps = load_json_capabilities()\n    cap_diff = compare_capabilities(ast_caps, json_caps)\n\n    # 7. 結果を1ファイルに統合保存\n    state = {\n        \"timestamp\": datetime.now().isoformat(),\n        \"doc_updates\": updates,\n        \"rule_violations\": rule_violations,\n        \"capability_diff\": cap_diff\n    }\n    write_file(STATE_PATH, json.dumps(state, ensure_ascii=False, indent=2))\n    print(f\"✅ kai_state.json updated → {STATE_PATH}\")", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://scripts/generate_kai_rules.py#call_gpt_for_rules", "code": "def call_gpt_for_rules(doc_text):\n    prompt = f\"\"\"\n以下は「プロジェクトKai」の定義・運用ルールに関するドキュメントです。\nKaiが「プロジェクトマネージャーAI」として活動する際に従うべき自己制御ルールを、次の形式のJSONで出力してください。\n\n- Kaiが自分自身に対して適用すべき制約や判断基準\n- 実行許可条件、禁止事項、承認要否などを含む\n- `id`, `description`, `scope`, `severity`を含む構造\n\n# ドキュメント内容:\n{doc_text}\n\n# 出力形式:\n{{\n  \"version\": \"1.0\",\n  \"rules\": [\n    {{\n      \"id\": \"rule_id\",\n      \"description\": \"説明文\",\n      \"scope\": \"対象領域（例：self_modification, document_update, git_ops など）\",\n      \"severity\": \"low / medium / high\"\n    }},\n    ...\n  ]\n}}\n\"\"\"\n\n    response = openai.chat.completions.create(\n        model=MODEL,\n        messages=[\n            {\"role\": \"system\", \"content\": \"あなたはプロジェクトマネジメントAI Kaiの監査ルールを定義する支援者です。\"},\n            {\"role\": \"user\", \"content\": prompt.strip()}\n        ]\n    )\n    return response.choices[0].message.content", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://scripts/generate_kai_rules.py#main", "code": "def main():\n    doc_text = load_docs()\n    gpt_output = call_gpt_for_rules(doc_text)\n    print(\"\\n===== GPT OUTPUT =====\\n\")\n    print(gpt_output)\n    print(\"\\n=======================\\n\")\n    parsed = parse_json_response(gpt_output)\n    if parsed:\n        os.makedirs(os.path.dirname(OUTPUT_PATH), exist_ok=True)\n        with open(OUTPUT_PATH, \"w\", encoding=\"utf-8\") as f:\n            json.dump(parsed, f, ensure_ascii=False, indent=2)\n        print(f\"✅ Generated: {OUTPUT_PATH} with {len(parsed['rules'])} rules.\")\n    else:\n        print(\"⚠ 解析失敗。\")", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://scripts/file_catalog.py#infer_type", "code": "def infer_type(filepath):\n    if filepath.endswith(\".md\"):\n        return \"doc\"\n    if filepath.endswith(\".json\"):\n        return \"data\"\n    if filepath.endswith(\".py\"):\n        if \"test\" in filepath.lower():\n            return \"script_test\"\n        if \"patch\" in filepath.lower():\n            return \"script_patch\"\n        return \"script\"\n    return \"other\"", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://scripts/file_catalog.py#infer_purpose", "code": "def infer_purpose(path):\n    lowered = path.lower()\n    if \"capabilities\" in lowered:\n        return \"Kai能力管理\"\n    if \"task\" in lowered:\n        return \"タスク管理\"\n    if \"log\" in lowered:\n        return \"ログ管理\"\n    if \"doc_update\" in lowered:\n        return \"ドキュメント更新\"\n    if \"approval\" in lowered:\n        return \"承認処理\"\n    if \"extract\" in lowered or \"scan\" in lowered:\n        return \"情報抽出・分析\"\n    if \"tag\" in lowered:\n        return \"タグ生成\"\n    return \"不明\"", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://scripts/file_catalog.py#main", "code": "def main():\n    result = build_catalog()\n    os.makedirs(os.path.dirname(OUTPUT_PATH), exist_ok=True)\n    with open(OUTPUT_PATH, \"w\", encoding=\"utf-8\") as f:\n        json.dump(result, f, ensure_ascii=False, indent=2)\n    print(f\"✅ ファイルカタログを保存しました: {OUTPUT_PATH}（{len(result)}件）\")", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://scripts/kai_autogen_one.py#request_skeleton", "code": "def request_skeleton(cap_id):\n    prompt = f\"機能ID: {cap_id} に対応する Kai の関数スケルトンを作ってください。\"\n    response = client.chat.completions.create(\n        model=\"gpt-4-1106-preview\",\n        messages=[\n            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n            {\"role\": \"user\", \"content\": prompt}\n        ],\n        temperature=0.3\n    )\n    return response.choices[0].message.content.strip()", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://scripts/kai_autogen_one.py#write_stub_file", "code": "def write_stub_file(cap_id, code_text):\n    os.makedirs(CORE_DIR, exist_ok=True)\n    filepath = os.path.join(CORE_DIR, f\"{cap_id}.py\")\n    with open(filepath, \"w\", encoding=\"utf-8\") as f:\n        f.write(code_text)\n    print(f\"✅ スケルトンを保存: {filepath}\")\n    return filepath", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://scripts/kai_autogen_one.py#write_patch_file", "code": "def write_patch_file(cap_id, priority, reason):\n    os.makedirs(PATCH_DIR, exist_ok=True)\n    patch_path = os.path.join(PATCH_DIR, f\"{cap_id}_capability.json\")\n    patch = {\n        \"id\": cap_id,\n        \"name\": cap_id.replace(\"_\", \" \").title(),\n        \"description\": reason,\n        \"priority\": priority,\n        \"requires_confirm\": True,\n        \"enabled\": True\n    }\n    with open(patch_path, \"w\", encoding=\"utf-8\") as f:\n        json.dump(patch, f, indent=2, ensure_ascii=False)\n    print(f\"📦 パッチ案を保存: {patch_path}\")\n    return patch_path", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://scripts/kai_autogen_one.py#main", "code": "def main():\n    next_task = select_next_task()\n    if not next_task:\n        print(\"🎉 すべての必要能力が実装済みです！\")\n        return\n\n    cap_id = next_task[\"id\"]\n    priority = next_task[\"priority\"]\n    reason = next_task[\"reason\"]\n\n    print(f\"🧠 GPTに依頼中: {cap_id}（優先度: {priority}）\")\n    raw_code = request_skeleton(cap_id)\n    clean_code = extract_python_code_block(raw_code)\n\n    print(\"\\n📄 生成スケルトン:\\n\")\n    print(clean_code)\n\n    write_stub_file(cap_id, clean_code)\n    write_patch_file(cap_id, priority, reason)", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://scripts/compare_capabilities.py#main", "code": "def main():\n    generated = load_json(GEN_PATH)\n    registered = load_json(REG_PATH)\n    registered_ids = extract_registered_ids(registered)\n    \n    patch = generate_patch_entries(generated, registered_ids)\n\n    with open(PATCH_PATH, \"w\", encoding=\"utf-8\") as f:\n        json.dump(patch, f, indent=2, ensure_ascii=False)\n\n    print(f\"Generated patch file with {len(patch)} new capabilities → {PATCH_PATH}\")", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://scripts/extract_inventory.py#should_ignore", "code": "def should_ignore(path: pathlib.Path) -> bool:\n    if ignore_spec is None:\n        return False\n    rel_path = str(path.relative_to(ROOT)).replace(os.sep, \"/\")\n    return ignore_spec.match_file(rel_path)", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://scripts/extract_inventory.py#py_items", "code": "def py_items(path):\n    tree = ast.parse(path.read_text(encoding=\"utf-8\"))\n    for node in ast.walk(tree):\n        if isinstance(node, ast.FunctionDef):\n            yield f\"code://{path.relative_to(ROOT)}#{node.name}\", \"function\", node.name\n        elif isinstance(node, ast.ClassDef):\n            yield f\"code://{path.relative_to(ROOT)}#{node.name}\", \"class\", node.name", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://scripts/extract_inventory.py#emit", "code": "def emit(uri, rtype, path, name):\n    print(json.dumps({\n        \"uri\": uri,\n        \"type\": rtype,\n        \"path\": str(path),\n        \"name\": name,\n        \"sha256\": hashlib.sha256(open(path, \"rb\").read()).hexdigest()[:8]\n    }), file=OUT.open(\"a\", encoding=\"utf-8\"))", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://scripts/propose_capability_code.py#main", "code": "def main():\n    load_dotenv()\n    patch = load_json(PATCH_PATH)\n    results = []\n    for item in patch:\n        try:\n            completed = call_gpt_capability_completion(item)\n            results.append(completed)\n        except Exception as e:\n            print(f\"Error: {e} on {item['id']}\")\n    save_json(results, OUTPUT_PATH)\n    print(f\"Saved completed capabilities to {OUTPUT_PATH}\")", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://scripts/frontmatter_scanner.py#main", "code": "def main():\n    capabilities = scan_all_markdown()\n    with open(OUTPUT_PATH, \"w\", encoding=\"utf-8\") as f:\n        json.dump(capabilities, f, indent=2, ensure_ascii=False)\n    print(f\"✅ Extracted {len(capabilities)} capabilities → {OUTPUT_PATH}\")", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://scripts/register_capabilities.py#merge_capabilities", "code": "def merge_capabilities(registered, new_caps):\n    registered_ids = {cap[\"id\"] for cap in registered}\n    merged = registered[:]\n    added = []\n    for cap in new_caps:\n        if cap[\"id\"] not in registered_ids:\n            cap.setdefault(\"enabled\", True)\n            cap.setdefault(\"requires_confirm\", False)\n            merged.append(cap)\n            added.append(cap)\n    return merged, added", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://scripts/register_capabilities.py#commit_changes", "code": "def commit_changes(file_path, message):\n    subprocess.run([\"git\", \"add\", file_path], check=True)\n    subprocess.run([\"git\", \"commit\", \"-m\", message], check=True)\n    print(f\"Committed changes: {message}\")", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://scripts/register_capabilities.py#main", "code": "def main():\n    new_caps = load_json(COMPLETE_PATH)\n    registered = load_json(REGISTRY_PATH)\n    merged, added = merge_capabilities(registered, new_caps)\n\n    if not added:\n        print(\"No new capabilities to register.\")\n        return\n\n    save_json(merged, REGISTRY_PATH)\n    print(f\"Added {len(added)} new capabilities to {REGISTRY_PATH}\")\n\n    commit_changes(REGISTRY_PATH, \"feat: register new Kai capabilities\")", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://scripts/scan_required_capabilities.py#main", "code": "def main():\n    data = extract_required_capabilities()\n    os.makedirs(os.path.dirname(OUTPUT_PATH), exist_ok=True)\n    with open(OUTPUT_PATH, \"w\", encoding=\"utf-8\") as f:\n        json.dump(data, f, ensure_ascii=False, indent=2)\n    print(f\"Generated {OUTPUT_PATH} with {len(data['required_capabilities'])} capability IDs.\")", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://scripts/scan_required_capabilities_gpt.py#call_gpt_analysis", "code": "def call_gpt_analysis(doc_text, capabilities_text):\n    prompt = f\"\"\"\n以下はプロジェクトKaiに関する定義やルール、進捗に関するドキュメントです。\nKaiがプロジェクトマネージャーとして機能するために必要な能力を、下記の能力リストから選んでください。\n\n# 能力一覧（capability list）:\n{capabilities_text}\n\n# ドキュメント内容:\n{doc_text}\n\n# 出力形式:\nJSON形式で以下のように出力してください：\n{{\n  \"role\": \"project_manager\",\n  \"required_capabilities\": [\"capability_id1\", \"capability_id2\", ...]\n}}\n\"\"\"\n\n    response = openai.chat.completions.create(\n        model=MODEL,\n        messages=[\n            {\"role\": \"system\", \"content\": \"あなたはプロジェクトマネージャー支援AIです。Kaiに必要な能力を提案してください。\"},\n            {\"role\": \"user\", \"content\": prompt.strip()}\n        ]\n    )\n    result = response.choices[0].message.content\n    print(\"\\n===== GPT OUTPUT =====\\n\")\n    print(result)\n    print(\"\\n=======================\\n\")\n    return result", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://scripts/scan_required_capabilities_gpt.py#main", "code": "def main():\n    doc_text = load_docs()\n    caps_text = \"\\n\".join(load_capabilities())\n    gpt_output = call_gpt_analysis(doc_text, caps_text)\n    parsed = parse_json_response(gpt_output)\n\n    if parsed:\n        os.makedirs(os.path.dirname(OUTPUT_PATH), exist_ok=True)\n        with open(OUTPUT_PATH, \"w\", encoding=\"utf-8\") as f:\n            json.dump(parsed, f, ensure_ascii=False, indent=2)\n        print(f\"✅ Generated: {OUTPUT_PATH} with {len(parsed['required_capabilities'])} capabilities.\")\n    else:\n        print(\"⚠ GPT出力の解析に失敗しました。\")", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://scripts/check_capability_overlap.py#discover_functions_with_decorator", "code": "def discover_functions_with_decorator():\n    results = {}\n    targets = [Path(BASE_DIR) / \"app.py\", *(Path(BASE_DIR) / \"core\").glob(\"*.py\")]\n    for file_path in targets:\n        if not file_path.is_file():\n            continue\n        with open(file_path, encoding=\"utf-8\") as f:\n            tree = ast.parse(f.read(), filename=str(file_path))\n        for node in ast.walk(tree):\n            if isinstance(node, ast.FunctionDef):\n                name = node.name\n                has_decorator = any(\n                    isinstance(deco, ast.Call) and getattr(deco.func, \"id\", \"\") == \"kai_capability\"\n                    for deco in node.decorator_list or []\n                )\n                results[name] = has_decorator\n    return results", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://scripts/check_capability_overlap.py#main", "code": "def main():\n    json_ids = set(load_json_capabilities())\n    decorator_map = discover_functions_with_decorator()\n    code_ids = set(decorator_map.keys())\n\n    only_in_json = json_ids - code_ids\n    classification = {}\n\n    for id_ in only_in_json:\n        if id_ in DECORATOR_IDS:\n            classification[id_] = \"helper_decorator\"\n        elif id_ in UTILITY_IDS:\n            classification[id_] = \"utility_function\"\n        elif id_ in MANUAL_ONLY:\n            classification[id_] = \"likely_manual\"\n        else:\n            classification[id_] = \"not_in_code\"\n\n    for id_ in (json_ids & code_ids):\n        if not decorator_map.get(id_, False):\n            classification[id_] = \"decorator_missing\"\n\n    print(\"\\n✅ Capability IDの差分・分類一覧\")\n    print(\"──────────────\")\n    for k, v in sorted(classification.items()):\n        print(f\"- {k}: {v}\")", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://scripts/test_core_functions.py#test_stub_writer", "code": "def test_stub_writer():\n    dummy = {\n        \"id\": \"test_capability\",\n        \"name\": \"テスト能力\",\n        \"description\": \"これはテスト用の能力です。\",\n        \"code\": '''def test_capability():\n    print(\"テスト能力実行\")'''\n    }\n    save_capability_stub(**dummy)\n    print(\"✅ スタブ保存完了: kai_generated/test_capability.py 等を確認してください\")", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://scripts/generate_capability_patches.py#request_skeleton", "code": "def request_skeleton(cap_id):\n    user_prompt = f\"機能ID: {cap_id}\\nこの機能の目的を踏まえ、Kaiが使用するPythonスケルトン関数を1つ作成してください。\"\n    response = client.chat.completions.create(\n        model=\"gpt-4-1106-preview\",\n        messages=[\n            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n            {\"role\": \"user\", \"content\": user_prompt}\n        ],\n        temperature=0.3\n    )\n    return response.choices[0].message.content.strip()", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://scripts/generate_capability_patches.py#main", "code": "def main():\n    priorities = load_priorities()\n    sorted_items = sorted(priorities.items(), key=lambda x: {\"high\": 0, \"medium\": 1, \"low\": 2}[x[1][\"priority\"]])\n\n    if not sorted_items:\n        print(\"📭 優先度付き能力がありません。\")\n        return\n\n    cap_id, meta = sorted_items[0]\n    print(f\"🧠 GPTにスケルトン生成を依頼中: {cap_id}\")\n    raw_code = request_skeleton(cap_id)\n    clean_code = extract_python_code_block(raw_code)\n\n    print(\"\\n📄 生成結果:\\n\")\n    print(clean_code)\n\n    save_skeleton_file(cap_id, clean_code)\n    save_capability_patch(cap_id, meta[\"reason\"])", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://scripts/register_capability_patch.py#main", "code": "def main():\n    if len(sys.argv) < 2:\n        print(\"❗ 使用方法: python scripts/register_capability_patch.py <capability_id>\")\n        return\n\n    cap_id = sys.argv[1]\n    register_capability(cap_id)", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://scripts/gen_master_snapshot.py#is_in_whitelist", "code": "def is_in_whitelist(path):\n    return any(path.startswith(os.path.join(REPO_ROOT, d)) for d in DIR_WHITELIST)", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://scripts/capability_diff.py#find_missing_capabilities", "code": "def find_missing_capabilities():\n    needed = load_json(NEEDED_CAPS_PATH)\n    kai = load_json(KAI_CAPS_PATH)\n\n    needed_ids = extract_needed_capability_ids(needed)\n    kai_ids = extract_kai_capability_ids(kai)\n\n    missing = needed_ids - kai_ids\n\n    return missing", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://scripts/capability_diff.py#main", "code": "def main():\n    missing = find_missing_capabilities()\n    if missing:\n        print(f\"❗ Missing capabilities ({len(missing)}):\")\n        for cap in sorted(missing):\n            print(f\" - {cap}\")\n    else:\n        print(\"✅ Kai already has all required capabilities!\")", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://scripts/add_capability_type.py#guess_type", "code": "def guess_type(cap):\n    # すでに type があれば尊重\n    if \"type\" in cap:\n        return cap[\"type\"]\n    fn = cap[\"id\"]\n    if CORE_PATTERN.match(fn):\n        return \"core\"\n    if fn.startswith((\"read_\", \"write_\", \"load_\", \"save_\", \"extract_\", \"ensure_\",\"safe_\")):\n        return \"utility\"\n    return \"core\"", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://scripts/add_capability_type.py#main", "code": "def main():\n    with open(CAP_PATH, encoding=\"utf-8\") as f:\n        caps = json.load(f)\n\n    updated = 0\n    for cap in caps:\n        new_type = guess_type(cap)\n        if cap.get(\"type\") != new_type:\n            cap[\"type\"] = new_type\n            updated += 1\n\n    with open(CAP_PATH, \"w\", encoding=\"utf-8\") as f:\n        json.dump(caps, f, indent=2, ensure_ascii=False)\n    print(f\"✅ type を更新 : {updated} 件\")", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://scripts/extract_capabilities.py#scan_python_files", "code": "def scan_python_files():\n    all_capabilities = []\n    for path in TARGET_DIRS:\n        if path.endswith(\".py\"):\n            paths_to_check = [path]\n        else:\n            paths_to_check = []\n            for root, dirs, files in os.walk(path):\n                dirs[:] = [d for d in dirs if d not in EXCLUDE_DIRS]\n                for file in files:\n                    if file.endswith(\".py\"):\n                        paths_to_check.append(os.path.join(root, file))\n\n        for file_path in paths_to_check:\n            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n                try:\n                    tree = ast.parse(f.read())\n                    capabilities = extract_functions_from_ast(tree, os.path.relpath(file_path))\n                    all_capabilities.extend(capabilities)\n                except Exception as e:\n                    print(f\"Error parsing {file_path}: {e}\")\n\n    return all_capabilities[:MAX_ENTRIES]", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://scripts/extract_capabilities.py#main", "code": "def main():\n    capabilities = scan_python_files()\n    with open(OUTPUT_PATH, \"w\", encoding=\"utf-8\") as f:\n        json.dump(capabilities, f, indent=2, ensure_ascii=False)\n    print(f\"Capabilities extracted to {OUTPUT_PATH} (limited to {MAX_ENTRIES} entries)\")", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://scripts/priority_proposer.py#propose_priorities", "code": "def propose_priorities(capability_ids):\n    user_prompt = f\"不足能力一覧: {capability_ids}\"\n    response = client.chat.completions.create(\n        model=\"gpt-4-1106-preview\",\n        messages=[\n            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n            {\"role\": \"user\", \"content\": user_prompt}\n        ],\n        temperature=0.4\n    )\n    return response.choices[0].message.content.strip()", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://scripts/priority_proposer.py#main", "code": "def main():\n    missing = list(find_missing_capabilities())\n    if not missing:\n        print(\"✅ 不足している能力はありません。\")\n        return\n\n    print(f\"📋 不足能力 ({len(missing)}件): {missing}\")\n    print(\"🧠 GPT に優先度を問い合わせます...\\n\")\n\n    raw_reply = propose_priorities(missing)\n\n    try:\n        parsed = json.loads(raw_reply)\n        save_outputs(parsed)\n        print(\"✅ 優先度リストを docs/capability_priorities.json に保存しました。\")\n    except json.JSONDecodeError:\n        print(\"⚠️ GPTの応答をJSONとして解析できませんでした。内容を手動確認してください：\\n\")\n        print(raw_reply)", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://scripts/self_state_builder.py#main", "code": "def main():\n    result = build_state()\n    os.makedirs(os.path.dirname(OUTPUT_PATH), exist_ok=True)\n    with open(OUTPUT_PATH, \"w\", encoding=\"utf-8\") as f:\n        json.dump(result, f, indent=2, ensure_ascii=False)\n    print(f\"✅ Kai自己状態ファイルを出力しました: {OUTPUT_PATH} ({len(result)} entries)\")", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
