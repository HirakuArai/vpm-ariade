{"resource": "code://core/handle_approval.py#handle_approval", "code": "def handle_approval(requester, document, approval_status):\n    \"\"\"\n    æŒ‡å®šã•ã‚ŒãŸãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®æ‰¿èªå‡¦ç†ã‚’è¡Œã„ã¾ã™ã€‚\n\n    Args:\n        requester (str): æ‰¿èªã‚’è¦æ±‚ã™ã‚‹ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®åå‰ã¾ãŸã¯IDã€‚\n        document (str): æ‰¿èªã¾ãŸã¯éæ‰¿èªã™ã‚‹ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®åå‰ã¾ãŸã¯IDã€‚\n        approval_status (bool): ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’æ‰¿èªã™ã‚‹å ´åˆã¯Trueã€éæ‰¿èªã™ã‚‹å ´åˆã¯Falseã€‚\n\n    Returns:\n        str: æ‰¿èªå‡¦ç†ã®çµæœã‚’èª¬æ˜ã™ã‚‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã€‚\n\n    ä½¿ã„æ–¹ã®ä¾‹:\n        # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ \"Doc123\" ã‚’ãƒ¦ãƒ¼ã‚¶ãƒ¼ \"User456\" ãŒæ‰¿èªã™ã‚‹å ´åˆ\n        result_message = handle_approval(\"User456\", \"Doc123\", True)\n        print(result_message)  # æ‰¿èªãŒå®Œäº†ã—ãŸæ—¨ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å‡ºåŠ›\n\n        # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ \"Doc789\" ã‚’ãƒ¦ãƒ¼ã‚¶ãƒ¼ \"User101\" ãŒéæ‰¿èªã™ã‚‹å ´åˆ\n        result_message = handle_approval(\"User101\", \"Doc789\", False)\n        print(result_message)  # éæ‰¿èªãŒå®Œäº†ã—ãŸæ—¨ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å‡ºåŠ›\n    \"\"\"\n    pass", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://core/structure_scanner.py#scan_project_structure", "code": "def scan_project_structure(base_path: str = \".\") -> Dict[str, List[str]]:\n    \"\"\"\n    ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ã¨ä¸»è¦ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’è¾æ›¸å½¢å¼ã§è¿”ã™ã€‚\n    \"\"\"\n    structure = {}\n    for root, dirs, files in os.walk(base_path):\n        if any(skip in root for skip in [\".venv\", \"__pycache__\", \".git\"]):\n            continue\n        rel_root = os.path.relpath(root, base_path)\n        if rel_root == \".\":\n            rel_root = \"\"\n        structure[rel_root] = sorted(files)\n    return structure", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://core/self_introspection.py#_norm", "code": "def _norm(val: str | None) -> str | None:\n    \"\"\"å¤§å°æ–‡å­—ãƒ»å‰å¾Œç©ºç™½ã‚’ç„¡è¦–ã—ãŸ ID æ­£è¦åŒ–\"\"\"\n    return None if val is None else val.strip().lower()", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://core/self_introspection.py#_id_set", "code": "def _id_set(lst: List[Dict[str, Any]]) -> Set[str]:\n    return {_norm(c.get(\"id\")) for c in lst if _norm(c.get(\"id\"))}", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://core/self_introspection.py#_fingerprint", "code": "def _fingerprint() -> str:\n    path = pathlib.Path(__file__)\n    md5 = hashlib.md5(path.read_bytes()).hexdigest()[:8]\n    mtime = dt.datetime.fromtimestamp(path.stat().st_mtime).strftime(\"%Y-%m-%d %H:%M:%S\")\n    return f\"{md5}@{mtime}\"", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://core/capabilities_registry.py#decorator", "code": "def decorator(fn):\n        fn._kai_capability = {\n            \"id\": id,\n            \"name\": name,\n            \"description\": description,\n            \"requires_confirm\": requires_confirm,\n            \"enabled\": enabled\n        }\n        return fn", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://core/git_ops.py#push_all_important_files", "code": "def push_all_important_files():\n    try:\n        subprocess.run([\"git\", \"config\", \"--global\", \"user.name\", \"Kai Bot\"], check=True)\n        subprocess.run([\"git\", \"config\", \"--global\", \"user.email\", \"kai@example.com\"], check=True)\n\n        # å¯¾è±¡ãƒ‘ã‚¿ãƒ¼ãƒ³\n        include_paths = [\n            \"data/*.json\",\n            \"data/structure_snapshot.json\",\n            \"output/*.json\",\n            \"conversations/*.md\",\n            \"logs/*.log\",\n            \"docs/*.md\",\n            \"core/**/*.py\",\n            \"scripts/*.py\"\n        ]\n\n        for pattern in include_paths:\n            subprocess.run([\"git\", \"add\", pattern], shell=False)\n\n        subprocess.run([\"git\", \"commit\", \"-m\", \"å…¨é‡è¦ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸€æ‹¬push\"], check=True)\n        subprocess.run([\n            \"git\", \"push\",\n            f\"https://{github_token}@github.com/HirakuArai/vpm-ariade.git\"\n        ], check=True)\n\n        print(\"âœ… é‡è¦ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å…¨ã¦pushã—ã¾ã—ãŸ\", flush=True)\n\n    except subprocess.CalledProcessError as e:\n        print(\"âŒ push_all_important_files ã‚¨ãƒ©ãƒ¼:\", e, flush=True)", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://core/run_code_analysis.py#main", "code": "def main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--file\", required=True, help=\"è§£æå¯¾è±¡ã®Pythonãƒ•ã‚¡ã‚¤ãƒ«\")\n    parser.add_argument(\"--mode\", choices=[\"functions\", \"classes\", \"variables\", \"all\"], default=\"all\")\n    args = parser.parse_args()\n\n    if args.mode in (\"functions\", \"all\"):\n        print(\"=== Functions ===\")\n        for f in extract_functions(args.file):\n            print(f\"- {f['name']}({', '.join(f['args'])}) @ line {f['lineno']}\")\n\n    if args.mode in (\"classes\", \"all\"):\n        print(\"\\n=== Classes ===\")\n        for c in extract_classes(args.file):\n            print(f\"- class {c['name']} (methods: {', '.join(c['methods'])}) @ line {c['lineno']}\")\n\n    if args.mode in (\"variables\", \"all\"):\n        print(\"\\n=== Variables ===\")\n        for v in extract_variables(args.file):\n            print(f\"- {v['name']} = {v['value']} ({v['type']}) @ line {v['lineno']}\")", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://core/log_utils.py#messages_to_text", "code": "def messages_to_text(messages):\n    text = \"\"\n    for m in messages:\n        role = m.get(\"role\", \"user\")\n        content = m.get(\"content\", \"\")\n        text += f\"{role.upper()}: {content}\\n\"\n    return text.strip()", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://core/enforcement.py#enforce_rules", "code": "def enforce_rules(action_context: dict) -> list:\n    \"\"\"\n    ä¸ãˆã‚‰ã‚ŒãŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«å¯¾ã—ã€kai_rules.json ã«åŸºã¥ããƒ«ãƒ¼ãƒ«é•åã‚’æ¤œå‡ºã™ã‚‹ã€‚\n    - action_context: {\n        \"action\": \"propose_doc_update\",\n        \"doc_type\": \"ondemand\",\n        \"approved\": False,\n        ...\n      }\n\n    Returns: é•åã—ãŸãƒ«ãƒ¼ãƒ«ã®ä¸€è¦§ï¼ˆç©ºãƒªã‚¹ãƒˆãªã‚‰å•é¡Œãªã—ï¼‰\n    \"\"\"\n    rules = load_rules()\n    violations = []\n\n    for rule in rules:\n        rid = rule.get(\"id\")\n        desc = rule.get(\"description\", \"\")\n        scope = rule.get(\"scope\")\n\n        # ä¾‹ï¼šç‰¹å®šãƒ«ãƒ¼ãƒ«ã«å¯¾ã™ã‚‹ç°¡æ˜“ãƒã‚§ãƒƒã‚¯ï¼ˆæ‹¡å¼µå¯ï¼‰\n        if rid == \"kai-on-demand-doc-block\":\n            if action_context.get(\"action\") in [\"propose_doc_update\", \"apply_update\"] and \\\n               action_context.get(\"doc_type\") == \"ondemand\":\n                violations.append(rule)\n\n        elif rid == \"kai-update-propose-approval\":\n            if action_context.get(\"action\") == \"apply_update\" and not action_context.get(\"approved\", False):\n                violations.append(rule)\n\n        elif rid == \"kai-single-doc-single-commit\":\n            if action_context.get(\"action\") == \"try_git_commit\" and \\\n               action_context.get(\"modified_docs\", 0) > 1:\n                violations.append(rule)\n\n        # TODO: è¿½åŠ ãƒ«ãƒ¼ãƒ«ãƒã‚§ãƒƒã‚¯ï¼ˆå°†æ¥ï¼‰\n\n    return violations", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://core/manage_tasks.py#create_task", "code": "def create_task(title, description, due_date, priority):\n    \"\"\"\n    æ–°ã—ã„ã‚¿ã‚¹ã‚¯ã‚’ä½œæˆã—ã€ä¿å­˜ã™ã‚‹ã€‚\n    ...\n    \"\"\"\n    pass", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://core/manage_tasks.py#delete_task", "code": "def delete_task(task_id):\n    \"\"\"\n    æŒ‡å®šã•ã‚ŒãŸIDã®ã‚¿ã‚¹ã‚¯ã‚’å‰Šé™¤ã™ã‚‹ã€‚\n    ...\n    \"\"\"\n    pass", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://core/manage_tasks.py#list_tasks", "code": "def list_tasks(filter_by=None, order_by=None):\n    \"\"\"\n    ä¿å­˜ã•ã‚Œã¦ã„ã‚‹ã‚¿ã‚¹ã‚¯ã®ãƒªã‚¹ãƒˆã‚’å–å¾—ã™ã‚‹ã€‚ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚„ã‚½ãƒ¼ãƒˆé †ã‚’æŒ‡å®šã§ãã‚‹ã€‚\n    ...\n    \"\"\"\n    pass", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://core/utils.py#read_file", "code": "def read_file(path):\n    \"\"\"\n    æŒ‡å®šã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿å–ã‚Šæ–‡å­—åˆ—ã¨ã—ã¦è¿”ã™ã€‚å­˜åœ¨ã—ãªã„å ´åˆã¯ç©ºæ–‡å­—åˆ—ã€‚\n    \"\"\"\n    return open(path, encoding=\"utf-8\").read() if os.path.exists(path) else \"\"", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://core/utils.py#write_file", "code": "def write_file(path, content):\n    \"\"\"\n    æŒ‡å®šã•ã‚ŒãŸãƒ‘ã‚¹ã«æ–‡å­—åˆ—ã‚’ä¿å­˜ã™ã‚‹ã€‚\n    \"\"\"\n    with open(path, \"w\", encoding=\"utf-8\") as f:\n        f.write(content)", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://core/utils.py#ensure_output_dir", "code": "def ensure_output_dir(path=\"kai_generated\"):\n    \"\"\"\n    æŒ‡å®šãƒ‘ã‚¹ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆï¼ˆæ—¢ã«å­˜åœ¨ã™ã‚Œã°ä½•ã‚‚ã—ãªã„ï¼‰ã€‚\n    \"\"\"\n    os.makedirs(path, exist_ok=True)", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://core/utils.py#safe_mkdir", "code": "def safe_mkdir(path):\n    \"\"\"\n    æŒ‡å®šã•ã‚ŒãŸãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆï¼ˆå­˜åœ¨ãƒã‚§ãƒƒã‚¯ä»˜ãï¼‰ã€‚\n    \"\"\"\n    os.makedirs(path, exist_ok=True)", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://core/decorator_inserter.py#insert_kai_decorator", "code": "def insert_kai_decorator(cap: Dict, *, dry_run=False) -> bool | str:\n    file_path = pathlib.Path(cap[\"filepath\"])\n    if not file_path.exists():\n        raise FileNotFoundError(file_path)\n\n    source_lines = file_path.read_text(encoding=\"utf-8\").splitlines()\n    tree = ast.parse(\"\\n\".join(source_lines))\n\n    target = next(\n        (n for n in ast.walk(tree)\n         if isinstance(n, ast.FunctionDef) and n.name == cap[\"name\"]),\n        None\n    )\n    if not target:\n        raise ValueError(f\"é–¢æ•° `{cap['name']}` ãŒ {file_path} ã«è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n\n    idx = target.lineno - 1\n\n    # ã™ã§ã«ç›´å‰ã«åŒã˜è£…é£¾ãŒã‚ã‚‹ãªã‚‰ã‚¹ã‚­ãƒƒãƒ—\n    if \"@kai_capability\" in source_lines[idx - 1]:\n        return False\n\n    # è£œå®Œå†…å®¹ï¼ˆdescriptionçœç•¥å¯ï¼‰\n    decorator = f\"@kai_capability(id=\\\\\\\"{cap['name']}\\\\\\\", name=\\\\\\\"{cap['name'].replace('_',' ').title()}\\\\\\\", description=\\\\\\\"KaiãŒ {cap['name']} ã«é–¢ã™ã‚‹èƒ½åŠ›ã‚’æä¾›ã—ã¾ã™ã€‚\\\\\\\", requires_confirm=False)\"\n\n    source_lines.insert(idx, decorator)\n    new_source = \"\\n\".join(source_lines) + \"\\n\"\n\n    if dry_run:\n        return new_source\n\n    file_path.write_text(new_source, encoding=\"utf-8\")\n    return True", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://core/kai_patch_applier.py#apply_gpt_patch", "code": "def apply_gpt_patch(markdown_text: str, fn_name: str, source_path: str = \"app.py\", auto_commit: bool = True) -> bool:\n    \"\"\"\n    GPTãŒè¿”ã—ãŸMarkdownå½¢å¼ã®ä¿®æ­£ææ¡ˆï¼ˆmarkdown_textï¼‰ã‹ã‚‰ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã‚’æŠ½å‡ºã—ã€\n    æŒ‡å®šã•ã‚ŒãŸé–¢æ•°(fn_name)ã«ä¸Šæ›¸ãã™ã‚‹ã€‚æˆåŠŸæ™‚ã« Git commit ã‚‚å®Ÿè¡Œã€‚\n    \"\"\"\n    code = extract_code_from_markdown(markdown_text)\n    if not code:\n        print(\"âŒ ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ãŒæŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚\")\n        return False\n\n    success = replace_function_in_source(source_path, fn_name, code)\n    if success:\n        # âœ… Patch log ã‚’è¨˜éŒ²\n        instruction = (\n            st.session_state.get(\"fn_instruction\", \"\") if \"st\" in globals() else\n            f\"é–¢æ•° `{fn_name}` ã‚’ GPT ã«ã‚ˆã‚Šè‡ªå‹•æ”¹ä¿®ï¼ˆKai UIã‹ã‚‰ï¼‰\"\n        )\n        log_patch(fn_name=fn_name, user_instruction=instruction, markdown_diff=markdown_text)\n\n        if auto_commit:\n            try_git_commit(source_path)\n            if os.path.exists(\"patch_history.json\"):\n                try_git_commit(\"patch_history.json\")\n\n    return success", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://core/discover_capabilities.py#discover_capabilities", "code": "def discover_capabilities(base_dir: str = \".\", full_scan: bool = False) -> list:\n    capabilities = []\n\n    # èµ°æŸ»å¯¾è±¡\n    targets = [\n        Path(base_dir) / \"app.py\",\n        *(Path(base_dir) / \"core\").glob(\"*.py\")\n    ]\n\n    for file_path in targets:\n        if not file_path.is_file():\n            continue\n\n        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n            tree = ast.parse(f.read(), filename=str(file_path))\n\n        for node in ast.walk(tree):\n            if isinstance(node, ast.FunctionDef):\n                meta = {\n                    \"id\": None,\n                    \"name\": node.name,\n                    \"description\": \"\",\n                    \"requires_confirm\": False,\n                    \"enabled\": True,\n                    \"decorated\": False\n                }\n                # ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ãƒã‚§ãƒƒã‚¯\n                for deco in node.decorator_list or []:\n                    if isinstance(deco, ast.Call) and getattr(deco.func, \"id\", \"\") == \"kai_capability\":\n                        for keyword in deco.keywords:\n                            meta[keyword.arg] = ast.literal_eval(keyword.value)\n                        meta[\"decorated\"] = True\n                if full_scan or meta[\"decorated\"]:\n                    capabilities.append(meta)\n\n    return capabilities", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://core/stub_writer.py#write_stub_file", "code": "def write_stub_file(id: str, code: str):\n    path = os.path.join(OUTPUT_DIR, f\"{id}.py\")\n    with open(path, \"w\", encoding=\"utf-8\") as f:\n        f.write(code)", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://core/stub_writer.py#write_metadata_file", "code": "def write_metadata_file(id: str, name: str, description: str):\n    meta = {\n        \"id\": id,\n        \"name\": name,\n        \"description\": description,\n        \"requires_confirm\": False,\n        \"enabled\": True\n    }\n    path = os.path.join(OUTPUT_DIR, f\"{id}_capability.json\")\n    with open(path, \"w\", encoding=\"utf-8\") as f:\n        json.dump(meta, f, ensure_ascii=False, indent=2)", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://core/code_rewriter.py#replace_function_in_source", "code": "def replace_function_in_source(source_path: str, fn_name: str, new_code: str) -> bool:\n    try:\n        with open(source_path, \"r\", encoding=\"utf-8\") as f:\n            source_lines = f.readlines()\n            tree = ast.parse(\"\".join(source_lines))\n\n        for node in tree.body:\n            if isinstance(node, ast.FunctionDef) and node.name == fn_name:\n                start = node.lineno - 1\n                end = node.end_lineno if hasattr(node, \"end_lineno\") else node.lineno + 5\n                break\n        else:\n            print(f\"âŒ é–¢æ•° '{fn_name}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚\")\n            return False\n\n        # new_code ã‚’ã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆè£œæ­£ã—ã¦æŒ¿å…¥\n        new_code_lines = [line + \"\\n\" for line in new_code.strip().splitlines()]\n        updated_lines = source_lines[:start] + new_code_lines + source_lines[end:]\n\n        with open(source_path, \"w\", encoding=\"utf-8\") as f:\n            f.writelines(updated_lines)\n\n        print(f\"âœ… é–¢æ•° '{fn_name}' ã‚’ä¸Šæ›¸ãã—ã¾ã—ãŸã€‚\")\n        return True\n\n    except Exception as e:\n        print(f\"âŒ æ›¸ãæ›ãˆã‚¨ãƒ©ãƒ¼: {e}\")\n        return False", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://core/capabilities_diff.py#compare_capabilities", "code": "def compare_capabilities(ast_caps: List[Dict[str, Any]], json_caps: List[Dict[str, Any]]) -> Dict[str, List[Dict[str, Any]]]:\n    \"\"\"\n    ASTçµæœã¨JSONå®šç¾©ã‚’æ¯”è¼ƒã—ã€å·®åˆ†ï¼ˆæœªç™»éŒ²ãƒ»ä¸ä¸€è‡´ï¼‰ã‚’è¿”ã™ã€‚\n\n    Returns:\n        {\n            \"missing_in_json\": [...],\n            \"mismatched\": [...]\n        }\n    \"\"\"\n    json_index = {cap[\"id\"]: cap for cap in json_caps if cap.get(\"id\")}\n    ast_index = {cap[\"id\"]: cap for cap in ast_caps if cap.get(\"id\")}\n\n    missing = []\n    mismatched = []\n\n    for id_, ast_cap in ast_index.items():\n        json_cap = json_index.get(id_)\n        if not json_cap:\n            missing.append(ast_cap)\n        else:\n            # æ¯”è¼ƒé …ç›®ï¼šname, description, requires_confirm, enabled\n            diffs = {}\n            for key in [\"name\", \"description\", \"requires_confirm\", \"enabled\"]:\n                if ast_cap.get(key) != json_cap.get(key):\n                    diffs[key] = {\n                        \"json\": json_cap.get(key),\n                        \"ast\": ast_cap.get(key)\n                    }\n            if diffs:\n                mismatched.append({\n                    \"id\": id_,\n                    \"differences\": diffs\n                })\n\n    return {\n        \"missing_in_json\": missing,\n        \"mismatched\": mismatched\n    }", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://core/capabilities_diff.py#format_diff_for_output", "code": "def format_diff_for_output(diff_result: Dict[str, List[Dict[str, Any]]]) -> str:\n    \"\"\"\n    å·®åˆ†çµæœã‚’Markdownå½¢å¼ã§æ•´å½¢ã—ã€å‡ºåŠ›ç”¨ã«ã™ã‚‹ã€‚\n    \"\"\"\n    lines = [\"# ğŸ” Kai è‡ªå·±èƒ½åŠ›å·®åˆ†ãƒã‚§ãƒƒã‚¯çµæœ\", \"\"]\n\n    if diff_result[\"missing_in_json\"]:\n        lines.append(\"## ğŸŸ¡ capabilities.jsonã«æœªç™»éŒ²ã®é–¢æ•°\")\n        for cap in diff_result[\"missing_in_json\"]:\n            lines.append(f\"- `{cap.get('id')}`: {cap.get('name')}\")\n        lines.append(\"\")\n\n    if diff_result[\"mismatched\"]:\n        lines.append(\"## ğŸŸ  å±æ€§ä¸ä¸€è‡´ã®é–¢æ•°\")\n        for mismatch in diff_result[\"mismatched\"]:\n            lines.append(f\"### ğŸ”§ `{mismatch['id']}`\")\n            for key, change in mismatch[\"differences\"].items():\n                lines.append(f\"- `{key}`: JSON = {change['json']} â†’ AST = {change['ast']}\")\n        lines.append(\"\")\n\n    if not lines[2:] and not lines[-1]:\n        lines.append(\"âœ… å·®åˆ†ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚ã™ã¹ã¦ä¸€è‡´ã—ã¦ã„ã¾ã™ã€‚\")\n\n    return \"\\n\".join(lines)", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://scripts/test_enforcement.py#test_on_demand_doc_block", "code": "def test_on_demand_doc_block():\n    context = {\n        \"action\": \"propose_doc_update\",\n        \"doc_type\": \"ondemand\"\n    }\n    violations = enforce_rules(context)\n    assert any(r[\"id\"] == \"kai-on-demand-doc-block\" for r in violations), \"Expected violation not found\"", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://scripts/test_enforcement.py#test_multi_doc_commit", "code": "def test_multi_doc_commit():\n    context = {\n        \"action\": \"try_git_commit\",\n        \"modified_docs\": 2\n    }\n    violations = enforce_rules(context)\n    assert any(r[\"id\"] == \"kai-single-doc-single-commit\" for r in violations), \"Expected violation not found\"", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://scripts/test_enforcement.py#test_valid_action", "code": "def test_valid_action():\n    context = {\n        \"action\": \"try_git_commit\",\n        \"modified_docs\": 1\n    }\n    violations = enforce_rules(context)\n    assert len(violations) == 0, \"Unexpected violations detected\"", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://scripts/sync_kai_state.py#sync_kai", "code": "def sync_kai():\n    # 1. æœ€æ–°ã®çŠ¶æ…‹ã«git pull\n    try_git_pull_safe()\n\n    # 2. æœªå‡¦ç†ãƒ­ã‚°ã®ç¢ºèªã¨ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ›´æ–°ææ¡ˆï¼ˆè‡ªå‹•æ‰¿èªï¼‰\n    unprocessed = check_unprocessed_logs()\n    updates = []\n    for fname in unprocessed:\n        doc_name = \"project_status.md\"  # å°†æ¥çš„ã«ãƒãƒƒãƒ”ãƒ³ã‚°å¯èƒ½ã«\n        messages = load_yesterdays_log_as_messages(fname)\n        conv_text = messages_to_text(messages)\n        proposal = propose_doc_update(doc_name, conv_text)\n        apply_update(doc_name, proposal, auto_approve=True)\n        updates.append(doc_name)\n\n    # 3. kai_rules.json å†ç”Ÿæˆ\n    subprocess.run([\"python\", \"scripts/generate_kai_rules.py\"])\n\n    # 4. å¿…è¦ãªèƒ½åŠ›ãƒªã‚¹ãƒˆã‚’å†ç”Ÿæˆï¼ˆGPTï¼‰\n    subprocess.run([\"python\", \"scripts/scan_required_capabilities_gpt.py\"])\n\n    # 5. ãƒ«ãƒ¼ãƒ«é•åã®æ¤œå‡ºï¼ˆä¾‹: è‡ªå‹•æ›´æ–°ã®ä¸­ã§ã®èª¤æ“ä½œãƒã‚§ãƒƒã‚¯ï¼‰\n    action_context = {\"action\": \"sync\", \"approved\": True}  # å¿…è¦ã«å¿œã˜ã¦æ‹¡å¼µ\n    rule_violations = enforce_rules(action_context)\n\n    # 6. ASTãƒ™ãƒ¼ã‚¹ã¨ç™»éŒ²æ¸ˆã¿capabilitiesã®å·®åˆ†ã‚’å–å¾—\n    ast_caps = load_ast_capabilities()\n    json_caps = load_json_capabilities()\n    cap_diff = compare_capabilities(ast_caps, json_caps)\n\n    # 7. çµæœã‚’1ãƒ•ã‚¡ã‚¤ãƒ«ã«çµ±åˆä¿å­˜\n    state = {\n        \"timestamp\": datetime.now().isoformat(),\n        \"doc_updates\": updates,\n        \"rule_violations\": rule_violations,\n        \"capability_diff\": cap_diff\n    }\n    write_file(STATE_PATH, json.dumps(state, ensure_ascii=False, indent=2))\n    print(f\"âœ… kai_state.json updated â†’ {STATE_PATH}\")", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://scripts/generate_kai_rules.py#call_gpt_for_rules", "code": "def call_gpt_for_rules(doc_text):\n    prompt = f\"\"\"\nä»¥ä¸‹ã¯ã€Œãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆKaiã€ã®å®šç¾©ãƒ»é‹ç”¨ãƒ«ãƒ¼ãƒ«ã«é–¢ã™ã‚‹ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã§ã™ã€‚\nKaiãŒã€Œãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼AIã€ã¨ã—ã¦æ´»å‹•ã™ã‚‹éš›ã«å¾“ã†ã¹ãè‡ªå·±åˆ¶å¾¡ãƒ«ãƒ¼ãƒ«ã‚’ã€æ¬¡ã®å½¢å¼ã®JSONã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚\n\n- KaiãŒè‡ªåˆ†è‡ªèº«ã«å¯¾ã—ã¦é©ç”¨ã™ã¹ãåˆ¶ç´„ã‚„åˆ¤æ–­åŸºæº–\n- å®Ÿè¡Œè¨±å¯æ¡ä»¶ã€ç¦æ­¢äº‹é …ã€æ‰¿èªè¦å¦ãªã©ã‚’å«ã‚€\n- `id`, `description`, `scope`, `severity`ã‚’å«ã‚€æ§‹é€ \n\n# ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå†…å®¹:\n{doc_text}\n\n# å‡ºåŠ›å½¢å¼:\n{{\n  \"version\": \"1.0\",\n  \"rules\": [\n    {{\n      \"id\": \"rule_id\",\n      \"description\": \"èª¬æ˜æ–‡\",\n      \"scope\": \"å¯¾è±¡é ˜åŸŸï¼ˆä¾‹ï¼šself_modification, document_update, git_ops ãªã©ï¼‰\",\n      \"severity\": \"low / medium / high\"\n    }},\n    ...\n  ]\n}}\n\"\"\"\n\n    response = openai.chat.completions.create(\n        model=MODEL,\n        messages=[\n            {\"role\": \"system\", \"content\": \"ã‚ãªãŸã¯ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆAI Kaiã®ç›£æŸ»ãƒ«ãƒ¼ãƒ«ã‚’å®šç¾©ã™ã‚‹æ”¯æ´è€…ã§ã™ã€‚\"},\n            {\"role\": \"user\", \"content\": prompt.strip()}\n        ]\n    )\n    return response.choices[0].message.content", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://scripts/generate_kai_rules.py#main", "code": "def main():\n    doc_text = load_docs()\n    gpt_output = call_gpt_for_rules(doc_text)\n    print(\"\\n===== GPT OUTPUT =====\\n\")\n    print(gpt_output)\n    print(\"\\n=======================\\n\")\n    parsed = parse_json_response(gpt_output)\n    if parsed:\n        os.makedirs(os.path.dirname(OUTPUT_PATH), exist_ok=True)\n        with open(OUTPUT_PATH, \"w\", encoding=\"utf-8\") as f:\n            json.dump(parsed, f, ensure_ascii=False, indent=2)\n        print(f\"âœ… Generated: {OUTPUT_PATH} with {len(parsed['rules'])} rules.\")\n    else:\n        print(\"âš  è§£æå¤±æ•—ã€‚\")", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://scripts/file_catalog.py#infer_type", "code": "def infer_type(filepath):\n    if filepath.endswith(\".md\"):\n        return \"doc\"\n    if filepath.endswith(\".json\"):\n        return \"data\"\n    if filepath.endswith(\".py\"):\n        if \"test\" in filepath.lower():\n            return \"script_test\"\n        if \"patch\" in filepath.lower():\n            return \"script_patch\"\n        return \"script\"\n    return \"other\"", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://scripts/file_catalog.py#infer_purpose", "code": "def infer_purpose(path):\n    lowered = path.lower()\n    if \"capabilities\" in lowered:\n        return \"Kaièƒ½åŠ›ç®¡ç†\"\n    if \"task\" in lowered:\n        return \"ã‚¿ã‚¹ã‚¯ç®¡ç†\"\n    if \"log\" in lowered:\n        return \"ãƒ­ã‚°ç®¡ç†\"\n    if \"doc_update\" in lowered:\n        return \"ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ›´æ–°\"\n    if \"approval\" in lowered:\n        return \"æ‰¿èªå‡¦ç†\"\n    if \"extract\" in lowered or \"scan\" in lowered:\n        return \"æƒ…å ±æŠ½å‡ºãƒ»åˆ†æ\"\n    if \"tag\" in lowered:\n        return \"ã‚¿ã‚°ç”Ÿæˆ\"\n    return \"ä¸æ˜\"", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://scripts/file_catalog.py#main", "code": "def main():\n    result = build_catalog()\n    os.makedirs(os.path.dirname(OUTPUT_PATH), exist_ok=True)\n    with open(OUTPUT_PATH, \"w\", encoding=\"utf-8\") as f:\n        json.dump(result, f, ensure_ascii=False, indent=2)\n    print(f\"âœ… ãƒ•ã‚¡ã‚¤ãƒ«ã‚«ã‚¿ãƒ­ã‚°ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {OUTPUT_PATH}ï¼ˆ{len(result)}ä»¶ï¼‰\")", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://scripts/kai_autogen_one.py#request_skeleton", "code": "def request_skeleton(cap_id):\n    prompt = f\"æ©Ÿèƒ½ID: {cap_id} ã«å¯¾å¿œã™ã‚‹ Kai ã®é–¢æ•°ã‚¹ã‚±ãƒ«ãƒˆãƒ³ã‚’ä½œã£ã¦ãã ã•ã„ã€‚\"\n    response = client.chat.completions.create(\n        model=\"gpt-4-1106-preview\",\n        messages=[\n            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n            {\"role\": \"user\", \"content\": prompt}\n        ],\n        temperature=0.3\n    )\n    return response.choices[0].message.content.strip()", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://scripts/kai_autogen_one.py#write_stub_file", "code": "def write_stub_file(cap_id, code_text):\n    os.makedirs(CORE_DIR, exist_ok=True)\n    filepath = os.path.join(CORE_DIR, f\"{cap_id}.py\")\n    with open(filepath, \"w\", encoding=\"utf-8\") as f:\n        f.write(code_text)\n    print(f\"âœ… ã‚¹ã‚±ãƒ«ãƒˆãƒ³ã‚’ä¿å­˜: {filepath}\")\n    return filepath", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://scripts/kai_autogen_one.py#write_patch_file", "code": "def write_patch_file(cap_id, priority, reason):\n    os.makedirs(PATCH_DIR, exist_ok=True)\n    patch_path = os.path.join(PATCH_DIR, f\"{cap_id}_capability.json\")\n    patch = {\n        \"id\": cap_id,\n        \"name\": cap_id.replace(\"_\", \" \").title(),\n        \"description\": reason,\n        \"priority\": priority,\n        \"requires_confirm\": True,\n        \"enabled\": True\n    }\n    with open(patch_path, \"w\", encoding=\"utf-8\") as f:\n        json.dump(patch, f, indent=2, ensure_ascii=False)\n    print(f\"ğŸ“¦ ãƒ‘ãƒƒãƒæ¡ˆã‚’ä¿å­˜: {patch_path}\")\n    return patch_path", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://scripts/kai_autogen_one.py#main", "code": "def main():\n    next_task = select_next_task()\n    if not next_task:\n        print(\"ğŸ‰ ã™ã¹ã¦ã®å¿…è¦èƒ½åŠ›ãŒå®Ÿè£…æ¸ˆã¿ã§ã™ï¼\")\n        return\n\n    cap_id = next_task[\"id\"]\n    priority = next_task[\"priority\"]\n    reason = next_task[\"reason\"]\n\n    print(f\"ğŸ§  GPTã«ä¾é ¼ä¸­: {cap_id}ï¼ˆå„ªå…ˆåº¦: {priority}ï¼‰\")\n    raw_code = request_skeleton(cap_id)\n    clean_code = extract_python_code_block(raw_code)\n\n    print(\"\\nğŸ“„ ç”Ÿæˆã‚¹ã‚±ãƒ«ãƒˆãƒ³:\\n\")\n    print(clean_code)\n\n    write_stub_file(cap_id, clean_code)\n    write_patch_file(cap_id, priority, reason)", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://scripts/compare_capabilities.py#main", "code": "def main():\n    generated = load_json(GEN_PATH)\n    registered = load_json(REG_PATH)\n    registered_ids = extract_registered_ids(registered)\n    \n    patch = generate_patch_entries(generated, registered_ids)\n\n    with open(PATCH_PATH, \"w\", encoding=\"utf-8\") as f:\n        json.dump(patch, f, indent=2, ensure_ascii=False)\n\n    print(f\"Generated patch file with {len(patch)} new capabilities â†’ {PATCH_PATH}\")", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://scripts/extract_inventory.py#should_ignore", "code": "def should_ignore(path: pathlib.Path) -> bool:\n    if ignore_spec is None:\n        return False\n    rel_path = str(path.relative_to(ROOT)).replace(os.sep, \"/\")\n    return ignore_spec.match_file(rel_path)", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://scripts/extract_inventory.py#py_items", "code": "def py_items(path):\n    tree = ast.parse(path.read_text(encoding=\"utf-8\"))\n    for node in ast.walk(tree):\n        if isinstance(node, ast.FunctionDef):\n            yield f\"code://{path.relative_to(ROOT)}#{node.name}\", \"function\", node.name\n        elif isinstance(node, ast.ClassDef):\n            yield f\"code://{path.relative_to(ROOT)}#{node.name}\", \"class\", node.name", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://scripts/extract_inventory.py#emit", "code": "def emit(uri, rtype, path, name):\n    print(json.dumps({\n        \"uri\": uri,\n        \"type\": rtype,\n        \"path\": str(path),\n        \"name\": name,\n        \"sha256\": hashlib.sha256(open(path, \"rb\").read()).hexdigest()[:8]\n    }), file=OUT.open(\"a\", encoding=\"utf-8\"))", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://scripts/propose_capability_code.py#main", "code": "def main():\n    load_dotenv()\n    patch = load_json(PATCH_PATH)\n    results = []\n    for item in patch:\n        try:\n            completed = call_gpt_capability_completion(item)\n            results.append(completed)\n        except Exception as e:\n            print(f\"Error: {e} on {item['id']}\")\n    save_json(results, OUTPUT_PATH)\n    print(f\"Saved completed capabilities to {OUTPUT_PATH}\")", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://scripts/frontmatter_scanner.py#main", "code": "def main():\n    capabilities = scan_all_markdown()\n    with open(OUTPUT_PATH, \"w\", encoding=\"utf-8\") as f:\n        json.dump(capabilities, f, indent=2, ensure_ascii=False)\n    print(f\"âœ… Extracted {len(capabilities)} capabilities â†’ {OUTPUT_PATH}\")", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://scripts/register_capabilities.py#merge_capabilities", "code": "def merge_capabilities(registered, new_caps):\n    registered_ids = {cap[\"id\"] for cap in registered}\n    merged = registered[:]\n    added = []\n    for cap in new_caps:\n        if cap[\"id\"] not in registered_ids:\n            cap.setdefault(\"enabled\", True)\n            cap.setdefault(\"requires_confirm\", False)\n            merged.append(cap)\n            added.append(cap)\n    return merged, added", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://scripts/register_capabilities.py#commit_changes", "code": "def commit_changes(file_path, message):\n    subprocess.run([\"git\", \"add\", file_path], check=True)\n    subprocess.run([\"git\", \"commit\", \"-m\", message], check=True)\n    print(f\"Committed changes: {message}\")", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://scripts/register_capabilities.py#main", "code": "def main():\n    new_caps = load_json(COMPLETE_PATH)\n    registered = load_json(REGISTRY_PATH)\n    merged, added = merge_capabilities(registered, new_caps)\n\n    if not added:\n        print(\"No new capabilities to register.\")\n        return\n\n    save_json(merged, REGISTRY_PATH)\n    print(f\"Added {len(added)} new capabilities to {REGISTRY_PATH}\")\n\n    commit_changes(REGISTRY_PATH, \"feat: register new Kai capabilities\")", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://scripts/scan_required_capabilities.py#main", "code": "def main():\n    data = extract_required_capabilities()\n    os.makedirs(os.path.dirname(OUTPUT_PATH), exist_ok=True)\n    with open(OUTPUT_PATH, \"w\", encoding=\"utf-8\") as f:\n        json.dump(data, f, ensure_ascii=False, indent=2)\n    print(f\"Generated {OUTPUT_PATH} with {len(data['required_capabilities'])} capability IDs.\")", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://scripts/scan_required_capabilities_gpt.py#call_gpt_analysis", "code": "def call_gpt_analysis(doc_text, capabilities_text):\n    prompt = f\"\"\"\nä»¥ä¸‹ã¯ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆKaiã«é–¢ã™ã‚‹å®šç¾©ã‚„ãƒ«ãƒ¼ãƒ«ã€é€²æ—ã«é–¢ã™ã‚‹ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã§ã™ã€‚\nKaiãŒãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã¨ã—ã¦æ©Ÿèƒ½ã™ã‚‹ãŸã‚ã«å¿…è¦ãªèƒ½åŠ›ã‚’ã€ä¸‹è¨˜ã®èƒ½åŠ›ãƒªã‚¹ãƒˆã‹ã‚‰é¸ã‚“ã§ãã ã•ã„ã€‚\n\n# èƒ½åŠ›ä¸€è¦§ï¼ˆcapability listï¼‰:\n{capabilities_text}\n\n# ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå†…å®¹:\n{doc_text}\n\n# å‡ºåŠ›å½¢å¼:\nJSONå½¢å¼ã§ä»¥ä¸‹ã®ã‚ˆã†ã«å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼š\n{{\n  \"role\": \"project_manager\",\n  \"required_capabilities\": [\"capability_id1\", \"capability_id2\", ...]\n}}\n\"\"\"\n\n    response = openai.chat.completions.create(\n        model=MODEL,\n        messages=[\n            {\"role\": \"system\", \"content\": \"ã‚ãªãŸã¯ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼æ”¯æ´AIã§ã™ã€‚Kaiã«å¿…è¦ãªèƒ½åŠ›ã‚’ææ¡ˆã—ã¦ãã ã•ã„ã€‚\"},\n            {\"role\": \"user\", \"content\": prompt.strip()}\n        ]\n    )\n    result = response.choices[0].message.content\n    print(\"\\n===== GPT OUTPUT =====\\n\")\n    print(result)\n    print(\"\\n=======================\\n\")\n    return result", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://scripts/scan_required_capabilities_gpt.py#main", "code": "def main():\n    doc_text = load_docs()\n    caps_text = \"\\n\".join(load_capabilities())\n    gpt_output = call_gpt_analysis(doc_text, caps_text)\n    parsed = parse_json_response(gpt_output)\n\n    if parsed:\n        os.makedirs(os.path.dirname(OUTPUT_PATH), exist_ok=True)\n        with open(OUTPUT_PATH, \"w\", encoding=\"utf-8\") as f:\n            json.dump(parsed, f, ensure_ascii=False, indent=2)\n        print(f\"âœ… Generated: {OUTPUT_PATH} with {len(parsed['required_capabilities'])} capabilities.\")\n    else:\n        print(\"âš  GPTå‡ºåŠ›ã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸã€‚\")", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://scripts/check_capability_overlap.py#discover_functions_with_decorator", "code": "def discover_functions_with_decorator():\n    results = {}\n    targets = [Path(BASE_DIR) / \"app.py\", *(Path(BASE_DIR) / \"core\").glob(\"*.py\")]\n    for file_path in targets:\n        if not file_path.is_file():\n            continue\n        with open(file_path, encoding=\"utf-8\") as f:\n            tree = ast.parse(f.read(), filename=str(file_path))\n        for node in ast.walk(tree):\n            if isinstance(node, ast.FunctionDef):\n                name = node.name\n                has_decorator = any(\n                    isinstance(deco, ast.Call) and getattr(deco.func, \"id\", \"\") == \"kai_capability\"\n                    for deco in node.decorator_list or []\n                )\n                results[name] = has_decorator\n    return results", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://scripts/check_capability_overlap.py#main", "code": "def main():\n    json_ids = set(load_json_capabilities())\n    decorator_map = discover_functions_with_decorator()\n    code_ids = set(decorator_map.keys())\n\n    only_in_json = json_ids - code_ids\n    classification = {}\n\n    for id_ in only_in_json:\n        if id_ in DECORATOR_IDS:\n            classification[id_] = \"helper_decorator\"\n        elif id_ in UTILITY_IDS:\n            classification[id_] = \"utility_function\"\n        elif id_ in MANUAL_ONLY:\n            classification[id_] = \"likely_manual\"\n        else:\n            classification[id_] = \"not_in_code\"\n\n    for id_ in (json_ids & code_ids):\n        if not decorator_map.get(id_, False):\n            classification[id_] = \"decorator_missing\"\n\n    print(\"\\nâœ… Capability IDã®å·®åˆ†ãƒ»åˆ†é¡ä¸€è¦§\")\n    print(\"â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\")\n    for k, v in sorted(classification.items()):\n        print(f\"- {k}: {v}\")", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://scripts/test_core_functions.py#test_stub_writer", "code": "def test_stub_writer():\n    dummy = {\n        \"id\": \"test_capability\",\n        \"name\": \"ãƒ†ã‚¹ãƒˆèƒ½åŠ›\",\n        \"description\": \"ã“ã‚Œã¯ãƒ†ã‚¹ãƒˆç”¨ã®èƒ½åŠ›ã§ã™ã€‚\",\n        \"code\": '''def test_capability():\n    print(\"ãƒ†ã‚¹ãƒˆèƒ½åŠ›å®Ÿè¡Œ\")'''\n    }\n    save_capability_stub(**dummy)\n    print(\"âœ… ã‚¹ã‚¿ãƒ–ä¿å­˜å®Œäº†: kai_generated/test_capability.py ç­‰ã‚’ç¢ºèªã—ã¦ãã ã•ã„\")", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://scripts/generate_capability_patches.py#request_skeleton", "code": "def request_skeleton(cap_id):\n    user_prompt = f\"æ©Ÿèƒ½ID: {cap_id}\\nã“ã®æ©Ÿèƒ½ã®ç›®çš„ã‚’è¸ã¾ãˆã€KaiãŒä½¿ç”¨ã™ã‚‹Pythonã‚¹ã‚±ãƒ«ãƒˆãƒ³é–¢æ•°ã‚’1ã¤ä½œæˆã—ã¦ãã ã•ã„ã€‚\"\n    response = client.chat.completions.create(\n        model=\"gpt-4-1106-preview\",\n        messages=[\n            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n            {\"role\": \"user\", \"content\": user_prompt}\n        ],\n        temperature=0.3\n    )\n    return response.choices[0].message.content.strip()", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://scripts/generate_capability_patches.py#main", "code": "def main():\n    priorities = load_priorities()\n    sorted_items = sorted(priorities.items(), key=lambda x: {\"high\": 0, \"medium\": 1, \"low\": 2}[x[1][\"priority\"]])\n\n    if not sorted_items:\n        print(\"ğŸ“­ å„ªå…ˆåº¦ä»˜ãèƒ½åŠ›ãŒã‚ã‚Šã¾ã›ã‚“ã€‚\")\n        return\n\n    cap_id, meta = sorted_items[0]\n    print(f\"ğŸ§  GPTã«ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆã‚’ä¾é ¼ä¸­: {cap_id}\")\n    raw_code = request_skeleton(cap_id)\n    clean_code = extract_python_code_block(raw_code)\n\n    print(\"\\nğŸ“„ ç”Ÿæˆçµæœ:\\n\")\n    print(clean_code)\n\n    save_skeleton_file(cap_id, clean_code)\n    save_capability_patch(cap_id, meta[\"reason\"])", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://scripts/register_capability_patch.py#main", "code": "def main():\n    if len(sys.argv) < 2:\n        print(\"â— ä½¿ç”¨æ–¹æ³•: python scripts/register_capability_patch.py <capability_id>\")\n        return\n\n    cap_id = sys.argv[1]\n    register_capability(cap_id)", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://scripts/gen_master_snapshot.py#is_in_whitelist", "code": "def is_in_whitelist(path):\n    return any(path.startswith(os.path.join(REPO_ROOT, d)) for d in DIR_WHITELIST)", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://scripts/capability_diff.py#find_missing_capabilities", "code": "def find_missing_capabilities():\n    needed = load_json(NEEDED_CAPS_PATH)\n    kai = load_json(KAI_CAPS_PATH)\n\n    needed_ids = extract_needed_capability_ids(needed)\n    kai_ids = extract_kai_capability_ids(kai)\n\n    missing = needed_ids - kai_ids\n\n    return missing", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://scripts/capability_diff.py#main", "code": "def main():\n    missing = find_missing_capabilities()\n    if missing:\n        print(f\"â— Missing capabilities ({len(missing)}):\")\n        for cap in sorted(missing):\n            print(f\" - {cap}\")\n    else:\n        print(\"âœ… Kai already has all required capabilities!\")", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://scripts/add_capability_type.py#guess_type", "code": "def guess_type(cap):\n    # ã™ã§ã« type ãŒã‚ã‚Œã°å°Šé‡\n    if \"type\" in cap:\n        return cap[\"type\"]\n    fn = cap[\"id\"]\n    if CORE_PATTERN.match(fn):\n        return \"core\"\n    if fn.startswith((\"read_\", \"write_\", \"load_\", \"save_\", \"extract_\", \"ensure_\",\"safe_\")):\n        return \"utility\"\n    return \"core\"", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://scripts/add_capability_type.py#main", "code": "def main():\n    with open(CAP_PATH, encoding=\"utf-8\") as f:\n        caps = json.load(f)\n\n    updated = 0\n    for cap in caps:\n        new_type = guess_type(cap)\n        if cap.get(\"type\") != new_type:\n            cap[\"type\"] = new_type\n            updated += 1\n\n    with open(CAP_PATH, \"w\", encoding=\"utf-8\") as f:\n        json.dump(caps, f, indent=2, ensure_ascii=False)\n    print(f\"âœ… type ã‚’æ›´æ–° : {updated} ä»¶\")", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://scripts/extract_capabilities.py#scan_python_files", "code": "def scan_python_files():\n    all_capabilities = []\n    for path in TARGET_DIRS:\n        if path.endswith(\".py\"):\n            paths_to_check = [path]\n        else:\n            paths_to_check = []\n            for root, dirs, files in os.walk(path):\n                dirs[:] = [d for d in dirs if d not in EXCLUDE_DIRS]\n                for file in files:\n                    if file.endswith(\".py\"):\n                        paths_to_check.append(os.path.join(root, file))\n\n        for file_path in paths_to_check:\n            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n                try:\n                    tree = ast.parse(f.read())\n                    capabilities = extract_functions_from_ast(tree, os.path.relpath(file_path))\n                    all_capabilities.extend(capabilities)\n                except Exception as e:\n                    print(f\"Error parsing {file_path}: {e}\")\n\n    return all_capabilities[:MAX_ENTRIES]", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://scripts/extract_capabilities.py#main", "code": "def main():\n    capabilities = scan_python_files()\n    with open(OUTPUT_PATH, \"w\", encoding=\"utf-8\") as f:\n        json.dump(capabilities, f, indent=2, ensure_ascii=False)\n    print(f\"Capabilities extracted to {OUTPUT_PATH} (limited to {MAX_ENTRIES} entries)\")", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://scripts/priority_proposer.py#propose_priorities", "code": "def propose_priorities(capability_ids):\n    user_prompt = f\"ä¸è¶³èƒ½åŠ›ä¸€è¦§: {capability_ids}\"\n    response = client.chat.completions.create(\n        model=\"gpt-4-1106-preview\",\n        messages=[\n            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n            {\"role\": \"user\", \"content\": user_prompt}\n        ],\n        temperature=0.4\n    )\n    return response.choices[0].message.content.strip()", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://scripts/priority_proposer.py#main", "code": "def main():\n    missing = list(find_missing_capabilities())\n    if not missing:\n        print(\"âœ… ä¸è¶³ã—ã¦ã„ã‚‹èƒ½åŠ›ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚\")\n        return\n\n    print(f\"ğŸ“‹ ä¸è¶³èƒ½åŠ› ({len(missing)}ä»¶): {missing}\")\n    print(\"ğŸ§  GPT ã«å„ªå…ˆåº¦ã‚’å•ã„åˆã‚ã›ã¾ã™...\\n\")\n\n    raw_reply = propose_priorities(missing)\n\n    try:\n        parsed = json.loads(raw_reply)\n        save_outputs(parsed)\n        print(\"âœ… å„ªå…ˆåº¦ãƒªã‚¹ãƒˆã‚’ docs/capability_priorities.json ã«ä¿å­˜ã—ã¾ã—ãŸã€‚\")\n    except json.JSONDecodeError:\n        print(\"âš ï¸ GPTã®å¿œç­”ã‚’JSONã¨ã—ã¦è§£æã§ãã¾ã›ã‚“ã§ã—ãŸã€‚å†…å®¹ã‚’æ‰‹å‹•ç¢ºèªã—ã¦ãã ã•ã„ï¼š\\n\")\n        print(raw_reply)", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
{"resource": "code://scripts/self_state_builder.py#main", "code": "def main():\n    result = build_state()\n    os.makedirs(os.path.dirname(OUTPUT_PATH), exist_ok=True)\n    with open(OUTPUT_PATH, \"w\", encoding=\"utf-8\") as f:\n        json.dump(result, f, indent=2, ensure_ascii=False)\n    print(f\"âœ… Kaiè‡ªå·±çŠ¶æ…‹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡ºåŠ›ã—ã¾ã—ãŸ: {OUTPUT_PATH} ({len(result)} entries)\")", "inferred_purpose": "__UNKNOWN__", "confidence": 0.0}
