# app.py  â€“  Kai (Streamlit Cloud)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒª importï¼ˆã™ã¹ã¦å…ˆé ­ã«é›†ç´„ï¼‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
import os
import json
import subprocess
from datetime import datetime
from zoneinfo import ZoneInfo
import pytz
import streamlit as st
import openai
from dotenv import load_dotenv

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# èªè¨¼ã‚­ãƒ¼ & ãƒ‘ã‚¹
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
load_dotenv()
openai.api_key = st.secrets.get("OPENAI_API_KEY") or os.getenv("OPENAI_API_KEY")
github_token = st.secrets.get("GITHUB_TOKEN") or os.getenv("GITHUB_TOKEN")

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DOCS_DIR = os.path.join(BASE_DIR, "docs")
CONV_DIR = os.path.join(BASE_DIR, "conversations")
FLAG_PATH = os.path.join(BASE_DIR, "check_flags", "processed_logs.json")
os.makedirs(CONV_DIR, exist_ok=True)
os.makedirs(os.path.dirname(FLAG_PATH), exist_ok=True)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ä¼šè©±ãƒ­ã‚°å‡¦ç†ç³» é–¢æ•°å®šç¾©
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def get_today_log_path() -> tuple:
    try:
        tokyo = pytz.timezone('Asia/Tokyo')
        today = datetime.now(tokyo)
        date_str = today.strftime('%Y-%m-%d')
        log_directory = "logs"
        os.makedirs(log_directory, exist_ok=True)
        log_path = f"{log_directory}/{date_str}.log"
        return date_str, log_path
    except Exception as e:
        print(f"âŒ get_today_log_path() ã§ã‚¨ãƒ©ãƒ¼: {e}", flush=True)
        return "unknown", "logs/unknown.log"

def append_to_log(role: str, content: str) -> None:
    ts = datetime.now(ZoneInfo("Asia/Tokyo")).strftime("%Y-%m-%d %H:%M:%S")
    _, path = get_today_log_path()
    with open(path, "a", encoding="utf-8") as f:
        f.write(f"## {ts} [ROLE: {role}]\n{content.strip()}\n\n")
    try_git_commit(path)

def load_conversation_messages():
    _, path = get_today_log_path()
    if not os.path.exists(path):
        return []
    msgs, cur_role, buf = [], None, []
    with open(path, encoding="utf-8") as f:
        for line in f:
            line = line.rstrip("\n")
            if line.startswith("## "):
                if cur_role and buf:
                    msgs.append({
                        "role": "user" if cur_role == "USER" else "assistant",
                        "content": "\n".join(buf)
                    })
                buf = []
                if "[ROLE: " in line:
                    cur_role = line.split("[ROLE: ")[1].split("]")[0]
            else:
                buf.append(line)
    if cur_role and buf:
        msgs.append({
            "role": "user" if cur_role == "USER" else "assistant",
            "content": "\n".join(buf)
        })
    return msgs

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# System ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def read_file(path: str) -> str:
    return open(path, encoding="utf-8").read() if os.path.exists(path) else ""

def get_system_prompt() -> str:
    overview   = read_file(os.path.join(DOCS_DIR, "architecture_overview.md"))
    base_rules = read_file(os.path.join(DOCS_DIR, "base_os_rules.md"))
    definition = read_file(os.path.join(DOCS_DIR, "project_definition.md"))
    status     = read_file(os.path.join(DOCS_DIR, "project_status.md"))
    return f"""{overview}

{base_rules}

ã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå®šç¾©ã€‘
{definition}

ã€ç¾åœ¨ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã€‘
{status if status.strip() else "ï¼ˆç¾åœ¨ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹æƒ…å ±ã¯ã‚ã‚Šã¾ã›ã‚“ï¼‰"}
"""

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Git: å®‰å…¨ã«pull â†’ commit â†’ push
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def try_git_pull_safe():
    try:
        subprocess.run(["git", "stash", "--include-untracked"], check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
        repo_url_with_token = f"https://{github_token}@github.com/HirakuArai/vpm-ariade.git"
        result = subprocess.run(
            ["git", "pull", "--rebase", repo_url_with_token],
            check=False,
            capture_output=True,
            text=True
        )
        if result.returncode != 0:
            print(f"âŒ Git pullå¤±æ•—: {result.stderr.strip()}", flush=True)
        else:
            print("âœ… å®‰å…¨ã«Git pullå®Œäº†", flush=True)
        subprocess.run(["git", "stash", "pop"], check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
    except subprocess.CalledProcessError as e:
        print(f"âŒ Git pullæ™‚ã®ä¾‹å¤–: {e}", flush=True)

def try_git_commit(file_path: str) -> None:
    if not github_token:
        return
    try:
        print(f"ğŸ“Œ Gitã‚³ãƒŸãƒƒãƒˆé–‹å§‹: {file_path}", flush=True)
        subprocess.run(["git", "config", "--global", "user.name", "Kai Bot"], check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
        subprocess.run(["git", "config", "--global", "user.email", "kai@example.com"], check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
        subprocess.run(["git", "add", file_path], check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
        subprocess.run(["git", "commit", "-m", f"Update log: {os.path.basename(file_path)}"], check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
        subprocess.run(["git", "push", f"https://{github_token}@github.com/HirakuArai/vpm-ariade.git"], check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
    except subprocess.CalledProcessError as e:
        print(f"âŒ Git pushå¤±æ•—: {e}", flush=True)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ä¼šè©±ãƒ­ã‚°ã®ç¢ºèªå‡¦ç†
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
import os
import json
import streamlit as st

def show_patch_log():
    """docs/patch_log.json ã‹ã‚‰ä¿®æ­£å±¥æ­´ã‚’èª­ã¿è¾¼ã¿ã€Streamlitã§è¡¨ç¤ºã—ã¾ã™ã€‚"""
    st.subheader("ğŸ“˜ ä¿®æ­£å±¥æ­´ãƒ­ã‚°ï¼ˆãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆï¼‰")
    patch_log_path = os.path.join("docs", "patch_log.json")

    if not os.path.exists(patch_log_path):
        st.info("ä¿®æ­£å±¥æ­´ã¯ã¾ã ã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    try:
        with open(patch_log_path, "r", encoding="utf-8") as f:
            patch_logs = json.load(f)
    except Exception as e:
        st.error(f"ä¿®æ­£å±¥æ­´ã®èª­ã¿è¾¼ã¿æ™‚ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return

    if not patch_logs:
        st.info("ä¿®æ­£å±¥æ­´ã¯ã¾ã ã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    # æ–°ã—ã„é †ã«ä¸¦ã³æ›¿ãˆï¼ˆä¿®æ­£æ—¥æ™‚ãŒ "timestamp" ã‚­ãƒ¼ç­‰ã«å…¥ã£ã¦ã„ã‚‹å‰æï¼‰
    patch_logs_sorted = sorted(
        patch_logs,
        key=lambda x: x.get("timestamp", ""),
        reverse=True
    )

    for log in patch_logs_sorted:
        dt = log.get("timestamp", "æ—¥æ™‚ä¸æ˜")
        fname = log.get("filename", "ãƒ•ã‚¡ã‚¤ãƒ«åä¸æ˜")
        diff = log.get("diff", "")

        with st.expander(f"{dt} â€” {fname}", expanded=False):
            st.write("**å·®åˆ†å†…å®¹ï¼š**")
            st.code(diff, language="diff")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Streamlit UIï¼ˆKai ãƒ¢ãƒ¼ãƒ‰åˆ‡ã‚Šæ›¿ãˆçµ±åˆç‰ˆï¼‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title="Kai - VPMã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ", page_icon="ğŸ§ ")
st.title("ğŸ§µ Virtual Project Manager - Kai")
st.caption("ãƒãƒ¼ã‚¸ãƒ§ãƒ³: 2025-04-25 Kaiä¿®æ­£æ–‡ææ¡ˆæ©Ÿèƒ½ã‚’UIçµ±åˆ")
st.write("ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«ã¤ã„ã¦ä½•ã§ã‚‚èã„ã¦ãã ã•ã„ã€‚")

from core.code_analysis import extract_functions
from core.patch_log import load_patch_history
from core import log_utils, doc_update_engine

# ãƒ¢ãƒ¼ãƒ‰åˆ‡ã‚Šæ›¿ãˆ
mode = st.sidebar.radio("ğŸ“‚ ãƒ¢ãƒ¼ãƒ‰é¸æŠ", ["ãƒãƒ£ãƒƒãƒˆ", "é–¢æ•°ä¿®æ­£", "ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ›´æ–°"])

if mode == "ãƒãƒ£ãƒƒãƒˆ":
    try_git_pull_safe()
    check_unprocessed_logs()
    history = load_conversation_messages()
    for m in history:
        with st.chat_message("user" if m["role"] == "user" else "assistant", avatar="ğŸ‘‹" if m["role"] == "user" else "ğŸ§ "):
            st.markdown(m["content"])
    user_input = st.chat_input("ã‚ãªãŸã®ç™ºè¨€")
    if user_input:
        with st.chat_message("user", avatar="ğŸ‘‹"):
            st.markdown(user_input)
        append_to_log("USER", user_input)
        messages = [{"role": "system", "content": get_system_prompt()}] + history + [{"role": "user", "content": user_input}]
        response = openai.ChatCompletion.create(model="gpt-4.1", messages=messages)
        reply = response.choices[0].message.content
        with st.chat_message("assistant", avatar="ğŸ§ "):
            st.markdown(reply)
        append_to_log("KAI", reply)

elif mode == "é–¢æ•°ä¿®æ­£":
    st.divider()
    st.subheader("ğŸ›  Kai è‡ªå·±æ”¹ä¿®ï¼šé–¢æ•°é¸æŠãƒ¢ãƒ¼ãƒ‰")
    function_list = extract_functions("app.py") + extract_functions("core/doc_update_engine.py")
    function_labels = [f"{f['name']} ({', '.join(f['args'])}) @ L{f['lineno']}" for f in function_list]
    selected_func_label = st.selectbox("ğŸ”§ ä¿®æ­£ã—ãŸã„é–¢æ•°ã‚’é¸ã‚“ã§ãã ã•ã„", function_labels)
    user_instruction = st.text_area("ğŸ“ ä¿®æ­£ã—ãŸã„å†…å®¹ã‚’å…·ä½“çš„ã«è¨˜å…¥ã—ã¦ãã ã•ã„")
    if st.button("ğŸ’¡ GPTã«ä¿®æ­£æ¡ˆã‚’ç”Ÿæˆã•ã›ã‚‹"):
        selected = function_list[function_labels.index(selected_func_label)]
        with open("app.py", encoding="utf-8") as f:
            lines = f.readlines()
        fn_source = "".join(lines[selected["lineno"] - 1 : selected.get("end_lineno", selected["lineno"] + 5)])
        system_prompt = "ã‚ãªãŸã¯ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆKaiã®ã‚³ãƒ¼ãƒ‰ä¿®æ­£è£œåŠ©AIã§ã™ã€‚ä»¥ä¸‹ã®é–¢æ•°ã«ã¤ã„ã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æŒ‡ç¤ºã‚’ã‚‚ã¨ã«æ”¹è‰¯æ¡ˆã‚’ææ¡ˆã—ã¦ãã ã•ã„ã€‚"
        user_prompt = f"# ä¿®æ­£å¯¾è±¡ã®é–¢æ•°\n```python\n{fn_source}\n```\n# ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æŒ‡ç¤º\n{user_instruction}\n# ææ¡ˆå†…å®¹ã‚’ Markdownå½¢å¼ã§è¨˜è¿°ã—ã¦ãã ã•ã„ã€‚"
        response = openai.ChatCompletion.create(
            model="gpt-4.1",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ]
        )
        proposal = response.choices[0].message["content"]
        st.session_state["fn_proposal"] = proposal
        st.session_state["fn_selected"] = selected["name"]
        st.session_state["fn_instruction"] = user_instruction
        st.markdown("### ğŸ’¬ ä¿®æ­£ææ¡ˆï¼ˆKaiã‹ã‚‰ï¼‰")
        st.code(proposal, language="markdown")

    fn_selected = st.session_state.get("fn_selected")
    if st.session_state.get("fn_proposal") and fn_selected:
        st.subheader("ğŸ”§ GPTã®ææ¡ˆã‚’é©ç”¨ã™ã‚‹")
        if st.button("ğŸ’¾ ä¿®æ­£ã‚’app.pyã«åæ˜ ï¼‹Gitã‚³ãƒŸãƒƒãƒˆ"):
            from core.kai_patch_applier import apply_gpt_patch
            success = apply_gpt_patch(
                markdown_text=st.session_state["fn_proposal"],
                fn_name=fn_selected,
                source_path="app.py",
                auto_commit=True
            )
            if success:
                st.success(f"âœ… é–¢æ•° `{fn_selected}` ã‚’æ›´æ–°ã—ã¾ã—ãŸï¼")
                st.toast("ğŸ’¾ ä¿®æ­£å†…å®¹ãŒå±¥æ­´ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸ", icon="ğŸ“œ")
                st.balloons()
            else:
                st.error(f"âŒ é–¢æ•° `{fn_selected}` ã®æ›´æ–°ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")

    st.divider()
    st.subheader("ğŸ“œ å·®åˆ†å±¥æ­´ãƒ­ã‚°ï¼ˆè‡ªå‹•ä¿å­˜ï¼‰")
    history_data = load_patch_history()
    if not history_data:
        st.info("ã¾ã ãƒ‘ãƒƒãƒå±¥æ­´ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
    else:
        for entry in reversed(history_data):
            with st.expander(f"ğŸ•’ {entry['timestamp']} | é–¢æ•°: {entry['function']}"):
                st.markdown(f"**æŒ‡ç¤ºå†…å®¹**:\n```\n{entry['instruction']}\n```")
                st.markdown(f"**ææ¡ˆã•ã‚ŒãŸä¿®æ­£**:\n```markdown\n{entry['diff']}\n```")

elif mode == "ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ›´æ–°":
    st.header("ğŸ§  ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ›´æ–°ææ¡ˆï¼ˆKaiï¼‰")
    md_files = [f for f in os.listdir(DOCS_DIR) if f.endswith(".md")]
    doc_name = st.selectbox("æ›´æ–°å¯¾è±¡ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’é¸æŠ", md_files)
    if st.button("ğŸ” GPTã§ä¿®æ­£ææ¡ˆã‚’ç¢ºèª"):
        messages = log_utils.load_yesterdays_log_as_messages()
        if not messages:
            st.warning("æ˜¨æ—¥ã®ä¼šè©±ãƒ­ã‚°ãŒè¦‹ã¤ã‹ã‚‰ãªã„ã€ã¾ãŸã¯ç©ºã§ã™ã€‚")
        else:
            conv_text = log_utils.messages_to_text(messages)
            with st.spinner("GPTãŒä¿®æ­£æ–‡ã‚’ç”Ÿæˆä¸­..."):
                proposal = doc_update_engine.propose_doc_update(doc_name, conv_text)
            st.subheader("ğŸ’¡ GPTä¿®æ­£ææ¡ˆ")
            st.code(proposal, language="diff")
            if st.button("âœ… ã“ã®ä¿®æ­£ã‚’åæ˜ ã—ã¦Gitã‚³ãƒŸãƒƒãƒˆ"):
                doc_update_engine.apply_update(doc_name, proposal, auto_approve=True)
                st.success("âœ… ã‚³ãƒŸãƒƒãƒˆå®Œäº†ï¼")
