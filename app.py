"""
Optimized Streamlitâ€‘Kai entrypoint.
- Focuses on **minimal, deterministic** prompt generation.
- Always pulls the latest project rules / definition / architecture & DSL.
- Selfâ€‘check utilities live in `selfcheck.py` (not shown here).
"""
from pathlib import Path
import json
from textwrap import dedent

import streamlit as st

ROOT = Path(__file__).resolve().parent
DOCS = ROOT / "docs"
DSL  = ROOT / "dsl"

def read(path: str | Path) -> str:
    return Path(path).read_text(encoding="utf-8")

def extract_section(md_path: Path, headings: list[str]) -> str:
    lines = read(md_path).splitlines()
    keep, buf = False, []
    for line in lines:
        if line.startswith("#"):
            title = line.lstrip("# ").strip()
            keep = title in headings
        if keep:
            buf.append(line)
    return "\n".join(buf)

def get_system_prompt() -> str:
    # (a) base_os_rules.mdï¼ˆYAML+å½¹å‰²å®£è¨€ä»˜ãï¼‰
    rules = read(DOCS / "base_os_rules.md")

    # (b) integrated_dsl.jsonlï¼ˆREADME+name/descriptionä¸€è¦§ï¼‰
    dsl_readme = ""
    dsl_readme_path = DSL / "README.md"
    if dsl_readme_path.exists():
        dsl_readme = read(dsl_readme_path)
    dsl_lines = []
    for raw in (DSL / "integrated_dsl.jsonl").read_text(encoding="utf-8").splitlines():
        try:
            item = json.loads(raw)
            name = item.get('name')
            desc = item.get('description')
            if not name or not desc:
                continue
            dsl_lines.append(f"- **{name}**: {desc}")
        except Exception:
            continue
    dsl_block = "\n".join([dsl_readme.strip()] + dsl_lines if dsl_readme else dsl_lines)

    # (c) project_definition.mdï¼ˆå½¹å‰²å®£è¨€ï¼‹æŠœç²‹ï¼‰
    proj = extract_section(DOCS / "project_definition.md", ["ç›®çš„", "ã‚´ãƒ¼ãƒ«", "Kai Support ã®å½¹å‰²"])

    # (d) architecture_overview.mdï¼ˆå½¹å‰²å®£è¨€ï¼‹æŠœç²‹ï¼‰
    arch = extract_section(DOCS / "architecture_overview.md", ["PoCæ§‹æˆ", "é‹ç”¨ãƒ•ãƒ­ãƒ¼"])

    return "\n\n".join([rules, dsl_block, proj, arch])

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Example usage inside Streamlit Kai (pseudoâ€‘code)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

st.set_page_config(page_title="Kai Chat", page_icon="ğŸ’¬")
st.title("ğŸ’¬ Kai - GPTãƒãƒ£ãƒƒãƒˆ")

if "history" not in st.session_state:
    st.session_state["history"] = []

# â‘  å±¥æ­´ã‚’ä¸Šã‹ã‚‰é †ã«è¡¨ç¤º
for msg in st.session_state["history"]:
    is_user = msg["role"] == "user"
    st.chat_message("user" if is_user else "assistant").markdown(msg["content"])

# â‘¡ å…¥åŠ›æ¬„ã‚’ä¸€ç•ªä¸‹ã«
user_input = st.text_input("ã‚ãªãŸã®ç™ºè¨€ï¼ˆé€ä¿¡ã§Enterï¼‰", "")

# å…¥åŠ›ãŒã‚ã‚Œã°é€ä¿¡
if user_input:
    import openai
    system_prompt = get_system_prompt()
    messages = [{"role": "system", "content": system_prompt}]
    for msg in st.session_state["history"]:
        messages.append(msg)
    messages.append({"role": "user", "content": user_input})
    response = openai.chat.completions.create(
        model="gpt-4.1",
        messages=messages
    )
    reply = response.choices[0].message.content
    st.session_state["history"].append({"role": "user", "content": user_input})
    st.session_state["history"].append({"role": "assistant", "content": reply})