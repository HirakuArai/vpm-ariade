import json, pathlib, re, hashlib, textwrap, os
from datetime import datetime

"""derive_intent_from_doc.py  â€“  M5.1 draft generator (OpenAI v1.x)

å…¥åŠ›:
  â€¢ docs/project_definition.md
  â€¢ docs/base_os_rules.md
  â€¢ data/kai_capabilities.jsonï¼ˆè£œåŠ©ãƒ¡ã‚¿ï¼‰

å‡ºåŠ›:
  â€¢ draft_dsl/intent_dsl_draft_<timestamp>.jsonl

å‡¦ç†æ¦‚è¦:
  1. Markdown ã‚’ OpenAI GPT ã§è§£æã— capability è¡Œã‚’æŠ½å‡º
  2. `- [id] purpose` ç®‡æ¡æ›¸ãã‚’æ­£è¦è¡¨ç¾ã§ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æŠ½å‡º
  3. æ—§ JSON ã‹ã‚‰ enabled / requires_confirm ã‚’è£œå®Œ
  4. confidence=0.4, status ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ä»˜ãã§ä¸‹æ›¸ãã‚’ç”Ÿæˆ

ä¾å­˜:
  - openai>=1.10.0,<2.0.0  (requirements.txt ã«åˆã‚ã›ã‚‹)
  - OPENAI_API_KEY ç’°å¢ƒå¤‰æ•°ãŒå¿…è¦
"""

from openai import OpenAI  # openai-python v1.x

ROOT = pathlib.Path(__file__).resolve().parent.parent.parent
DOCS = ROOT / "docs"
DRAFT_DIR = ROOT / "draft_dsl"
DRAFT_DIR.mkdir(exist_ok=True)

TARGET_FILES = {"project_definition.md", "base_os_rules.md"}
GPT_MODEL = os.getenv("GPT_MODEL", "gpt-4o-mini")

# --------------------------------------------------------------------
# Helpers
# --------------------------------------------------------------------

def sha2568(path: pathlib.Path) -> str:
    return hashlib.sha256(path.read_bytes()).hexdigest()[:8]

REGEX_CAP = re.compile(r"^-\s*\[(?P<id>[^\]]+)\]\s+(?P<purpose>.+)$", re.MULTILINE)

def regex_extract(md_text: str):
    for m in REGEX_CAP.finditer(md_text):
        yield {
            "id": m.group("id"),
            "inferred_purpose": m.group("purpose"),
            "confidence": 0.4,
            "enabled": True,
            "requires_confirm": False,
            "status": "ok",
        }

def gpt_extract(md_text: str, client: OpenAI):
    prompt = textwrap.dedent(f"""
    ã‚ãªãŸã¯ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢PMã§ã™ã€‚æ¬¡ã® Markdown å®šç¾©æ›¸ã‹ã‚‰ Kai/VPM ãŒå®Ÿè£…ã™ã¹ã capability æƒ…å ±ã‚’ JSON Lines ã§æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚
    å„è¡Œã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã¯: id, inferred_purpose, enabled (bool), requires_confirm (bool), status(ok|missing|conflict)ã€‚
    æ¬ è½/çŸ›ç›¾ãŒã‚ã‚Œã° status ã‚’å¤‰æ›´ã—ã€purpose ã«ç°¡æ½”ã«è¦ç´„ã‚’æ›¸ã„ã¦ãã ã•ã„ã€‚
    JSONLines ä»¥å¤–ã®å‡ºåŠ›ã¯ç¦æ­¢ã—ã¾ã™ã€‚
    ---
    {md_text[:8000]}
    ---
    ä¾‹: {{"id":"task_scheduler","inferred_purpose":"ã‚¿ã‚¹ã‚¯ã‚’ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«å®Ÿè¡Œ","enabled":true,"requires_confirm":false,"status":"ok"}}
    """)
    try:
        rsp = client.chat.completions.create(
            model=GPT_MODEL,
            messages=[{"role": "user", "content": prompt}],
            temperature=0.2,
        )
        lines = rsp.choices[0].message.content.strip().splitlines()
        for l in lines:
            try:
                rec = json.loads(l)
                rec.setdefault("confidence", 0.4)
                yield rec
            except Exception:
                continue
    except Exception as e:
        print("âš ï¸ GPT æŠ½å‡ºå¤±æ•—:", e)
        return []


def load_old_cap_json():
    for p in [ROOT / "data" / "kai_capabilities.json", DOCS / "kai_capabilities.json"]:
        if p.exists():
            return {c["id"]: c for c in json.load(open(p, encoding="utf-8"))}
    return {}

# --------------------------------------------------------------------
# Main pipeline
# --------------------------------------------------------------------

def main():
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        raise RuntimeError("OPENAI_API_KEY not set")
    client = OpenAI(api_key=api_key)

    records: dict[str, dict] = {}

    for md_path in DOCS.glob("*.md"):
        if md_path.name not in TARGET_FILES:
            continue
        md_text = md_path.read_text(encoding="utf-8")
        # 1) GPT æŠ½å‡º
        for rec in gpt_extract(md_text, client):
            rec.setdefault("observed_state", {})["sha256"] = sha2568(md_path)
            rec["resource"] = f"intent://{md_path.relative_to(ROOT)}#{rec['id']}"
            rec["dsl_version"] = "0.1"
            records[rec["id"]] = rec
        # 2) æ­£è¦è¡¨ç¾ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        for rec in regex_extract(md_text):
            rec.setdefault("observed_state", {})["sha256"] = sha2568(md_path)
            rec["resource"] = f"intent://{md_path.relative_to(ROOT)}#{rec['id']}"
            rec["dsl_version"] = "0.1"
            records.setdefault(rec["id"], rec)  # GPTå„ªå…ˆ

    # 3) è£œåŠ©ãƒ¡ã‚¿ã®ãƒãƒ¼ã‚¸
    old_caps = load_old_cap_json()
    for cid, meta in old_caps.items():
        rec = records.setdefault(
            cid,
            {
                "id": cid,
                "resource": f"intent://legacy/{cid}",
                "inferred_purpose": meta.get("purpose", "ç›®çš„ä¸æ˜"),
                "confidence": 0.4,
                "dsl_version": "0.1",
                "status": "ok",
            },
        )
        rec["enabled"] = meta.get("enabled", True)
        rec["requires_confirm"] = meta.get("requires_confirm", False)

    # 4) Draft æ›¸ãå‡ºã—
    ts = datetime.utcnow().strftime("%Y%m%d-%H%M%S")
    out_path = DRAFT_DIR / f"intent_dsl_draft_{ts}.jsonl"
    with open(out_path, "w", encoding="utf-8") as f:
        for r in records.values():
            f.write(json.dumps(r, ensure_ascii=False) + "\n")

    print(f"ğŸ“ Draft DSL written to {out_path}")

if __name__ == "__main__":
    main()
